[2023-09-11 00:48:17] [marian] Marian v1.12.0 3daf4ee2 2023-04-15 00:25:50 -0700
[2023-09-11 00:48:17] [marian] Running on mlc6 as process 32 with command line:
[2023-09-11 00:48:17] [marian] /data/rw/evgeny/opus-training/3rd_party/marian-dev/build//marian --model /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz -c configs/model/student.yml configs/training/student.finetune.yml --train-sets /data/rw/evgeny/data/fi-en/opusprod/filtered/corpus.fi.gz /data/rw/evgeny/data/fi-en/opusprod/filtered/corpus.en.gz -T /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/tmp --shuffle-in-ram --vocabs /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm -w 18000 --devices 0 1 2 3 4 5 6 7 --sharding local --sync-sgd --valid-metrics perplexity chrf ce-mean-words bleu-detok --valid-sets /data/rw/evgeny/data/fi-en/opusprod/original/devset.fi.gz /data/rw/evgeny/data/fi-en/opusprod/original/devset.en.gz --valid-translation-output /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/devset.out --quiet-translation --overwrite --keep-best --log /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/train.log --valid-log /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/valid.log --pretrained-model /data/rw/evgeny/models/fi-en/opusprod/student/final.model.npz.best-perplexity.npz --guided-alignment /data/rw/evgeny/data/fi-en/opusprod/alignment/corpus.aln.gz
[2023-09-11 00:48:17] [config] after: 0e
[2023-09-11 00:48:17] [config] after-batches: 0
[2023-09-11 00:48:17] [config] after-epochs: 0
[2023-09-11 00:48:17] [config] all-caps-every: 0
[2023-09-11 00:48:17] [config] allow-unk: false
[2023-09-11 00:48:17] [config] authors: false
[2023-09-11 00:48:17] [config] beam-size: 1
[2023-09-11 00:48:17] [config] bert-class-symbol: "[CLS]"
[2023-09-11 00:48:17] [config] bert-mask-symbol: "[MASK]"
[2023-09-11 00:48:17] [config] bert-masking-fraction: 0.15
[2023-09-11 00:48:17] [config] bert-sep-symbol: "[SEP]"
[2023-09-11 00:48:17] [config] bert-train-type-embeddings: true
[2023-09-11 00:48:17] [config] bert-type-vocab-size: 2
[2023-09-11 00:48:17] [config] build-info: ""
[2023-09-11 00:48:17] [config] check-gradient-nan: false
[2023-09-11 00:48:17] [config] check-nan: false
[2023-09-11 00:48:17] [config] cite: false
[2023-09-11 00:48:17] [config] clip-norm: 0
[2023-09-11 00:48:17] [config] cost-scaling:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] cost-type: ce-mean-words
[2023-09-11 00:48:17] [config] cpu-threads: 0
[2023-09-11 00:48:17] [config] data-threads: 8
[2023-09-11 00:48:17] [config] data-weighting: ""
[2023-09-11 00:48:17] [config] data-weighting-type: sentence
[2023-09-11 00:48:17] [config] dec-cell: ssru
[2023-09-11 00:48:17] [config] dec-cell-base-depth: 2
[2023-09-11 00:48:17] [config] dec-cell-high-depth: 1
[2023-09-11 00:48:17] [config] dec-depth: 2
[2023-09-11 00:48:17] [config] devices:
[2023-09-11 00:48:17] [config]   - 0
[2023-09-11 00:48:17] [config]   - 1
[2023-09-11 00:48:17] [config]   - 2
[2023-09-11 00:48:17] [config]   - 3
[2023-09-11 00:48:17] [config]   - 4
[2023-09-11 00:48:17] [config]   - 5
[2023-09-11 00:48:17] [config]   - 6
[2023-09-11 00:48:17] [config]   - 7
[2023-09-11 00:48:17] [config] dim-emb: 256
[2023-09-11 00:48:17] [config] dim-rnn: 1024
[2023-09-11 00:48:17] [config] dim-vocabs:
[2023-09-11 00:48:17] [config]   - 32000
[2023-09-11 00:48:17] [config]   - 32000
[2023-09-11 00:48:17] [config] disp-first: 10
[2023-09-11 00:48:17] [config] disp-freq: 100
[2023-09-11 00:48:17] [config] disp-label-counts: true
[2023-09-11 00:48:17] [config] dropout-rnn: 0
[2023-09-11 00:48:17] [config] dropout-src: 0
[2023-09-11 00:48:17] [config] dropout-trg: 0
[2023-09-11 00:48:17] [config] dump-config: ""
[2023-09-11 00:48:17] [config] dynamic-gradient-scaling:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] early-stopping: 20
[2023-09-11 00:48:17] [config] early-stopping-on: first
[2023-09-11 00:48:17] [config] embedding-fix-src: false
[2023-09-11 00:48:17] [config] embedding-fix-trg: false
[2023-09-11 00:48:17] [config] embedding-normalization: false
[2023-09-11 00:48:17] [config] embedding-vectors:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] enc-cell: gru
[2023-09-11 00:48:17] [config] enc-cell-depth: 1
[2023-09-11 00:48:17] [config] enc-depth: 6
[2023-09-11 00:48:17] [config] enc-type: bidirectional
[2023-09-11 00:48:17] [config] english-title-case-every: 0
[2023-09-11 00:48:17] [config] exponential-smoothing: True
[2023-09-11 00:48:17] [config] factor-weight: 1
[2023-09-11 00:48:17] [config] factors-combine: sum
[2023-09-11 00:48:17] [config] factors-dim-emb: 0
[2023-09-11 00:48:17] [config] gradient-checkpointing: false
[2023-09-11 00:48:17] [config] gradient-norm-average-window: 100
[2023-09-11 00:48:17] [config] guided-alignment: /data/rw/evgeny/data/fi-en/opusprod/alignment/corpus.aln.gz
[2023-09-11 00:48:17] [config] guided-alignment-cost: ce
[2023-09-11 00:48:17] [config] guided-alignment-weight: 0.1
[2023-09-11 00:48:17] [config] ignore-model-config: false
[2023-09-11 00:48:17] [config] input-types:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] interpolate-env-vars: false
[2023-09-11 00:48:17] [config] keep-best: true
[2023-09-11 00:48:17] [config] label-smoothing: 0
[2023-09-11 00:48:17] [config] layer-normalization: false
[2023-09-11 00:48:17] [config] learn-rate: 0.0003
[2023-09-11 00:48:17] [config] lemma-dependency: ""
[2023-09-11 00:48:17] [config] lemma-dim-emb: 0
[2023-09-11 00:48:17] [config] log: /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/train.log
[2023-09-11 00:48:17] [config] log-level: info
[2023-09-11 00:48:17] [config] log-time-zone: ""
[2023-09-11 00:48:17] [config] logical-epoch:
[2023-09-11 00:48:17] [config]   - 1e
[2023-09-11 00:48:17] [config]   - 0
[2023-09-11 00:48:17] [config] lr-decay: 0
[2023-09-11 00:48:17] [config] lr-decay-freq: 50000
[2023-09-11 00:48:17] [config] lr-decay-inv-sqrt:
[2023-09-11 00:48:17] [config]   - 32000
[2023-09-11 00:48:17] [config] lr-decay-repeat-warmup: false
[2023-09-11 00:48:17] [config] lr-decay-reset-optimizer: false
[2023-09-11 00:48:17] [config] lr-decay-start:
[2023-09-11 00:48:17] [config]   - 10
[2023-09-11 00:48:17] [config]   - 1
[2023-09-11 00:48:17] [config] lr-decay-strategy: epoch+stalled
[2023-09-11 00:48:17] [config] lr-report: True
[2023-09-11 00:48:17] [config] lr-warmup: 16000
[2023-09-11 00:48:17] [config] lr-warmup-at-reload: false
[2023-09-11 00:48:17] [config] lr-warmup-cycle: false
[2023-09-11 00:48:17] [config] lr-warmup-start-rate: 0
[2023-09-11 00:48:17] [config] max-length: 200
[2023-09-11 00:48:17] [config] max-length-crop: false
[2023-09-11 00:48:17] [config] max-length-factor: 3
[2023-09-11 00:48:17] [config] maxi-batch: 1000
[2023-09-11 00:48:17] [config] maxi-batch-sort: trg
[2023-09-11 00:48:17] [config] mini-batch: 1000
[2023-09-11 00:48:17] [config] mini-batch-fit: True
[2023-09-11 00:48:17] [config] mini-batch-fit-step: 10
[2023-09-11 00:48:17] [config] mini-batch-round-up: true
[2023-09-11 00:48:17] [config] mini-batch-track-lr: false
[2023-09-11 00:48:17] [config] mini-batch-warmup: 0
[2023-09-11 00:48:17] [config] mini-batch-words: 0
[2023-09-11 00:48:17] [config] mini-batch-words-ref: 0
[2023-09-11 00:48:17] [config] model: /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 00:48:17] [config] multi-loss-type: sum
[2023-09-11 00:48:17] [config] n-best: false
[2023-09-11 00:48:17] [config] no-nccl: false
[2023-09-11 00:48:17] [config] no-reload: false
[2023-09-11 00:48:17] [config] no-restore-corpus: false
[2023-09-11 00:48:17] [config] normalize: 1
[2023-09-11 00:48:17] [config] normalize-gradient: false
[2023-09-11 00:48:17] [config] num-devices: 0
[2023-09-11 00:48:17] [config] optimizer: adam
[2023-09-11 00:48:17] [config] optimizer-delay: 4
[2023-09-11 00:48:17] [config] optimizer-params:
[2023-09-11 00:48:17] [config]   - 0.9
[2023-09-11 00:48:17] [config]   - 0.98
[2023-09-11 00:48:17] [config]   - 1e-09
[2023-09-11 00:48:17] [config] output-omit-bias: false
[2023-09-11 00:48:17] [config] overwrite: true
[2023-09-11 00:48:17] [config] precision:
[2023-09-11 00:48:17] [config]   - float32
[2023-09-11 00:48:17] [config]   - float32
[2023-09-11 00:48:17] [config] pretrained-model: /data/rw/evgeny/models/fi-en/opusprod/student/final.model.npz.best-perplexity.npz
[2023-09-11 00:48:17] [config] quantize-biases: false
[2023-09-11 00:48:17] [config] quantize-bits: 8
[2023-09-11 00:48:17] [config] quantize-log-based: false
[2023-09-11 00:48:17] [config] quantize-optimization-steps: 0
[2023-09-11 00:48:17] [config] quiet: false
[2023-09-11 00:48:17] [config] quiet-translation: true
[2023-09-11 00:48:17] [config] relative-paths: false
[2023-09-11 00:48:17] [config] right-left: false
[2023-09-11 00:48:17] [config] save-freq: 500
[2023-09-11 00:48:17] [config] seed: 0
[2023-09-11 00:48:17] [config] sentencepiece-alphas:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] sentencepiece-max-lines: 2000000
[2023-09-11 00:48:17] [config] sentencepiece-options: ""
[2023-09-11 00:48:17] [config] sharding: local
[2023-09-11 00:48:17] [config] shuffle: data
[2023-09-11 00:48:17] [config] shuffle-in-ram: true
[2023-09-11 00:48:17] [config] sigterm: save-and-exit
[2023-09-11 00:48:17] [config] skip: false
[2023-09-11 00:48:17] [config] sqlite: ""
[2023-09-11 00:48:17] [config] sqlite-drop: false
[2023-09-11 00:48:17] [config] sync-freq: 200u
[2023-09-11 00:48:17] [config] sync-sgd: true
[2023-09-11 00:48:17] [config] tempdir: /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/tmp
[2023-09-11 00:48:17] [config] tied-embeddings: false
[2023-09-11 00:48:17] [config] tied-embeddings-all: true
[2023-09-11 00:48:17] [config] tied-embeddings-src: false
[2023-09-11 00:48:17] [config] train-embedder-rank:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] train-sets:
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/data/fi-en/opusprod/filtered/corpus.fi.gz
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/data/fi-en/opusprod/filtered/corpus.en.gz
[2023-09-11 00:48:17] [config] transformer-aan-activation: swish
[2023-09-11 00:48:17] [config] transformer-aan-depth: 2
[2023-09-11 00:48:17] [config] transformer-aan-nogate: false
[2023-09-11 00:48:17] [config] transformer-decoder-autoreg: rnn
[2023-09-11 00:48:17] [config] transformer-decoder-dim-ffn: 0
[2023-09-11 00:48:17] [config] transformer-decoder-ffn-depth: 0
[2023-09-11 00:48:17] [config] transformer-depth-scaling: false
[2023-09-11 00:48:17] [config] transformer-dim-aan: 2048
[2023-09-11 00:48:17] [config] transformer-dim-ffn: 1536
[2023-09-11 00:48:17] [config] transformer-dropout: 0
[2023-09-11 00:48:17] [config] transformer-dropout-attention: 0
[2023-09-11 00:48:17] [config] transformer-dropout-ffn: 0
[2023-09-11 00:48:17] [config] transformer-ffn-activation: relu
[2023-09-11 00:48:17] [config] transformer-ffn-depth: 2
[2023-09-11 00:48:17] [config] transformer-guided-alignment-layer: last
[2023-09-11 00:48:17] [config] transformer-heads: 8
[2023-09-11 00:48:17] [config] transformer-no-projection: false
[2023-09-11 00:48:17] [config] transformer-pool: false
[2023-09-11 00:48:17] [config] transformer-postprocess: dan
[2023-09-11 00:48:17] [config] transformer-postprocess-emb: d
[2023-09-11 00:48:17] [config] transformer-postprocess-top: ""
[2023-09-11 00:48:17] [config] transformer-preprocess: ""
[2023-09-11 00:48:17] [config] transformer-rnn-projection: false
[2023-09-11 00:48:17] [config] transformer-tied-layers:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] transformer-train-position-embeddings: false
[2023-09-11 00:48:17] [config] tsv: false
[2023-09-11 00:48:17] [config] tsv-fields: 0
[2023-09-11 00:48:17] [config] type: transformer
[2023-09-11 00:48:17] [config] ulr: false
[2023-09-11 00:48:17] [config] ulr-dim-emb: 0
[2023-09-11 00:48:17] [config] ulr-dropout: 0
[2023-09-11 00:48:17] [config] ulr-keys-vectors: ""
[2023-09-11 00:48:17] [config] ulr-query-vectors: ""
[2023-09-11 00:48:17] [config] ulr-softmax-temperature: 1
[2023-09-11 00:48:17] [config] ulr-trainable-transformation: false
[2023-09-11 00:48:17] [config] unlikelihood-loss: false
[2023-09-11 00:48:17] [config] valid-freq: 500
[2023-09-11 00:48:17] [config] valid-log: /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/valid.log
[2023-09-11 00:48:17] [config] valid-max-length: 1000
[2023-09-11 00:48:17] [config] valid-metrics:
[2023-09-11 00:48:17] [config]   - perplexity
[2023-09-11 00:48:17] [config]   - chrf
[2023-09-11 00:48:17] [config]   - ce-mean-words
[2023-09-11 00:48:17] [config]   - bleu-detok
[2023-09-11 00:48:17] [config] valid-mini-batch: 16
[2023-09-11 00:48:17] [config] valid-reset-all: false
[2023-09-11 00:48:17] [config] valid-reset-stalled: false
[2023-09-11 00:48:17] [config] valid-script-args:
[2023-09-11 00:48:17] [config]   []
[2023-09-11 00:48:17] [config] valid-script-path: ""
[2023-09-11 00:48:17] [config] valid-sets:
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/data/fi-en/opusprod/original/devset.fi.gz
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/data/fi-en/opusprod/original/devset.en.gz
[2023-09-11 00:48:17] [config] valid-translation-output: /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/devset.out
[2023-09-11 00:48:17] [config] vocabs:
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm
[2023-09-11 00:48:17] [config]   - /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm
[2023-09-11 00:48:17] [config] word-penalty: 0
[2023-09-11 00:48:17] [config] word-scores: false
[2023-09-11 00:48:17] [config] workspace: 18000
[2023-09-11 00:48:17] [config] Model is being created with Marian v1.12.0 3daf4ee2 2023-04-15 00:25:50 -0700
[2023-09-11 00:48:17] Using synchronous SGD
[2023-09-11 00:48:17] [comm] Compiled without MPI support. Running as a single process on mlc6
[2023-09-11 00:48:17] Synced seed 1694386097
[2023-09-11 00:48:17] [data] Loading SentencePiece vocabulary from file /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm
[2023-09-11 00:48:17] [data] Setting vocabulary size for input 0 to 32,000
[2023-09-11 00:48:17] [data] Loading SentencePiece vocabulary from file /data/rw/evgeny/models/fi-en/opusprod/vocab/vocab.spm
[2023-09-11 00:48:17] [data] Setting vocabulary size for input 1 to 32,000
[2023-09-11 00:48:17] [data] Using word alignments from file /data/rw/evgeny/data/fi-en/opusprod/alignment/corpus.aln.gz
[2023-09-11 00:48:17] [batching] Collecting statistics for batch fitting with step size 10
[2023-09-11 00:48:18] [memory] Extending reserved space to 18048 MB (device gpu0)
[2023-09-11 00:48:19] [memory] Extending reserved space to 18048 MB (device gpu1)
[2023-09-11 00:48:19] [memory] Extending reserved space to 18048 MB (device gpu2)
[2023-09-11 00:48:20] [memory] Extending reserved space to 18048 MB (device gpu3)
[2023-09-11 00:48:20] [memory] Extending reserved space to 18048 MB (device gpu4)
[2023-09-11 00:48:20] [memory] Extending reserved space to 18048 MB (device gpu5)
[2023-09-11 00:48:21] [memory] Extending reserved space to 18048 MB (device gpu6)
[2023-09-11 00:48:21] [memory] Extending reserved space to 18048 MB (device gpu7)
[2023-09-11 00:48:21] [comm] Using NCCL 2.8.3 for GPU communication
[2023-09-11 00:48:21] [comm] Using global sharding
[2023-09-11 00:48:22] [comm] NCCLCommunicators constructed successfully
[2023-09-11 00:48:22] [training] Using 8 GPUs
[2023-09-11 00:48:22] [logits] Applying loss function for 1 factor(s)
[2023-09-11 00:48:22] [memory] Reserving 64 MB, device gpu0
[2023-09-11 00:48:23] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2023-09-11 00:48:23] [memory] Reserving 64 MB, device gpu0
[2023-09-11 00:49:06] [batching] Done. Typical MB size is 1,041,584 target words
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu0)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu1)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu2)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu3)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu4)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu5)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu6)
[2023-09-11 00:49:07] [memory] Extending reserved space to 18048 MB (device gpu7)
[2023-09-11 00:49:07] [comm] Using NCCL 2.8.3 for GPU communication
[2023-09-11 00:49:07] [comm] Using global sharding
[2023-09-11 00:49:08] [comm] NCCLCommunicators constructed successfully
[2023-09-11 00:49:08] [training] Using 8 GPUs
[2023-09-11 00:49:08] [training] Initializing model weights with pre-trained model /data/rw/evgeny/models/fi-en/opusprod/student/final.model.npz.best-perplexity.npz
[2023-09-11 00:49:09] No checkpoint found, parameters reloaded from last inference model
[2023-09-11 00:49:09] Training started
[2023-09-11 00:49:09] [data] Shuffling data
[2023-09-11 00:52:43] [data] Done reading 117,618,061 sentences
[2023-09-11 00:52:51] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 00:53:03] [training] Batches are processed as 1 process(es) x 8 devices/process
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu2
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu0
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu5
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu7
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu1
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu6
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu4
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu3
[2023-09-11 00:53:03] [memory] Reserving 64 MB, device gpu0
[2023-09-11 00:53:04] [memory] Reserving 64 MB, device gpu2
[2023-09-11 00:53:05] [memory] Reserving 64 MB, device gpu5
[2023-09-11 00:53:06] [memory] Reserving 64 MB, device gpu7
[2023-09-11 00:53:07] [memory] Reserving 64 MB, device gpu1
[2023-09-11 00:53:07] [memory] Reserving 64 MB, device gpu6
[2023-09-11 00:53:08] [memory] Reserving 64 MB, device gpu4
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu3
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu6
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu7
[2023-09-11 00:53:09] Quantizing the model to 8-bits
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu0
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu5
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu3
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu4
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu1
[2023-09-11 00:53:09] [memory] Reserving 64 MB, device gpu2
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu7
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu6
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu5
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu0
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu3
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu4
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu1
[2023-09-11 00:53:09] [memory] Reserving 4 B, device gpu2
[2023-09-11 00:53:09] Allocating memory for general optimizer shards
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu5
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu2
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu3
[2023-09-11 00:53:09] Parameter type float32, optimization type float32, casting types false
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu7
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu1
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu4
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu6
[2023-09-11 00:53:09] [memory] Reserving 8 MB, device gpu0
[2023-09-11 00:53:09] Allocating memory for Adam-specific shards
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu5
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu2
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu3
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu7
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu1
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu6
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu4
[2023-09-11 00:53:09] [memory] Reserving 16 MB, device gpu0
[2023-09-11 00:53:09] Ep. 1 : Up. 1 : Sen. 22,400 : Cost 0.42945915 : Time 242.90s : 1600.90 words/s : gNorm 0.3028 : L.r. 1.8750e-08
[2023-09-11 00:53:10] Ep. 1 : Up. 2 : Sen. 40,800 : Cost 0.43385255 : Time 0.69s : 620093.04 words/s : gNorm 0.3022 : L.r. 3.7500e-08
[2023-09-11 00:53:11] Ep. 1 : Up. 3 : Sen. 48,512 : Cost 0.44706488 : Time 0.80s : 535057.13 words/s : gNorm 0.3190 : L.r. 5.6250e-08
[2023-09-11 00:53:11] Ep. 1 : Up. 4 : Sen. 70,912 : Cost 0.42464179 : Time 0.58s : 582540.80 words/s : gNorm 0.3044 : L.r. 7.5000e-08
[2023-09-11 00:53:12] Ep. 1 : Up. 5 : Sen. 109,716 : Cost 0.43045926 : Time 0.75s : 672397.58 words/s : gNorm 0.3078 : L.r. 9.3750e-08
[2023-09-11 00:53:13] Ep. 1 : Up. 6 : Sen. 132,116 : Cost 0.42448750 : Time 0.63s : 640719.38 words/s : gNorm 0.2979 : L.r. 1.1250e-07
[2023-09-11 00:53:14] Ep. 1 : Up. 7 : Sen. 143,860 : Cost 0.44767788 : Time 0.73s : 627707.66 words/s : gNorm 0.3054 : L.r. 1.3125e-07
[2023-09-11 00:53:14] Ep. 1 : Up. 8 : Sen. 149,460 : Cost 0.46901628 : Time 0.87s : 538549.45 words/s : gNorm 0.3349 : L.r. 1.5000e-07
[2023-09-11 00:53:15] Ep. 1 : Up. 9 : Sen. 161,204 : Cost 0.45137054 : Time 0.73s : 653297.11 words/s : gNorm 0.3298 : L.r. 1.6875e-07
[2023-09-11 00:53:16] Ep. 1 : Up. 10 : Sen. 176,724 : Cost 0.43862325 : Time 0.67s : 704617.37 words/s : gNorm 0.3267 : L.r. 1.8750e-07
[2023-09-11 00:54:18] Ep. 1 : Up. 100 : Sen. 1,988,245 : Cost 0.44293833 : Time 62.12s : 624799.04 words/s : gNorm 0.3432 : L.r. 1.8750e-06
[2023-09-11 00:55:32] Ep. 1 : Up. 200 : Sen. 4,044,783 : Cost 0.44180658 : Time 73.80s : 609363.67 words/s : gNorm 0.3064 : L.r. 3.7500e-06
[2023-09-11 00:56:43] Ep. 1 : Up. 300 : Sen. 6,040,776 : Cost 0.44082555 : Time 71.74s : 610456.94 words/s : gNorm 0.3112 : L.r. 5.6250e-06
[2023-09-11 00:57:56] Ep. 1 : Up. 400 : Sen. 8,026,819 : Cost 0.43916216 : Time 72.22s : 606176.23 words/s : gNorm 0.2604 : L.r. 7.5000e-06
[2023-09-11 00:59:08] Ep. 1 : Up. 500 : Sen. 10,037,885 : Cost 0.43592939 : Time 72.29s : 605841.35 words/s : gNorm 0.2231 : L.r. 9.3750e-06
[2023-09-11 00:59:08] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 00:59:09] Saving Adam parameters
[2023-09-11 00:59:09] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 00:59:11] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 00:59:11] [valid] Ep. 1 : Up. 500 : perplexity : 9.44136 : new best
[2023-09-11 00:59:12] [valid] First sentence's tokens as scored:
[2023-09-11 00:59:12] [valid] Decoding validation set with SentencePieceVocab for scoring
[2023-09-11 00:59:12] [valid]   Hyp: R e i d m a n a g e d t o d r i v e N e w Z e a l a n d ' s A 1 G P c a r , B l a c k B e a u t y , o v e r s e v e n t i m e s t h e b r i d g e a t s p e e d s o f m o r e t h a n 1 6 0 k m / h .
[2023-09-11 00:59:12] [valid]   Ref: M r R e i d m a n a g e d t o d r i v e t h e N e w Z e a l a n d ' s A 1 G P c a r , B l a c k B e a u t y a t s p e e d s o v e r 1 6 0 k m / h s e v e n t i m e s o v e r t h e b r i d g e .
[2023-09-11 00:59:12] [valid] References contain unknown word, metric scores may be inaccurate
[2023-09-11 00:59:27] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-chrf.npz
[2023-09-11 00:59:27] [valid] Ep. 1 : Up. 500 : chrf : 56.4569 : new best
[2023-09-11 00:59:28] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 00:59:28] [valid] Ep. 1 : Up. 500 : ce-mean-words : 2.2451 : new best
[2023-09-11 00:59:37] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-bleu-detok.npz
[2023-09-11 00:59:38] [valid] Ep. 1 : Up. 500 : bleu-detok : 29.1717 : new best
[2023-09-11 01:00:49] Ep. 1 : Up. 600 : Sen. 12,096,400 : Cost 0.43422392 : Time 100.64s : 437122.89 words/s : gNorm 0.2136 : L.r. 1.1250e-05
[2023-09-11 01:02:02] Ep. 1 : Up. 700 : Sen. 14,054,254 : Cost 0.43195471 : Time 73.16s : 605920.87 words/s : gNorm 0.2129 : L.r. 1.3125e-05
[2023-09-11 01:03:16] Ep. 1 : Up. 800 : Sen. 16,156,263 : Cost 0.42985243 : Time 74.14s : 604111.59 words/s : gNorm 0.1995 : L.r. 1.5000e-05
[2023-09-11 01:04:30] Ep. 1 : Up. 900 : Sen. 18,175,872 : Cost 0.42936045 : Time 73.83s : 604887.29 words/s : gNorm 0.1995 : L.r. 1.6875e-05
[2023-09-11 01:05:44] Ep. 1 : Up. 1000 : Sen. 20,312,610 : Cost 0.42563558 : Time 74.09s : 604047.69 words/s : gNorm 0.2063 : L.r. 1.8750e-05
[2023-09-11 01:05:44] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:05:44] Saving Adam parameters
[2023-09-11 01:05:45] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:05:47] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 01:05:47] [valid] Ep. 1 : Up. 1000 : perplexity : 9.39711 : new best
[2023-09-11 01:06:01] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-chrf.npz
[2023-09-11 01:06:01] [valid] Ep. 1 : Up. 1000 : chrf : 56.555 : new best
[2023-09-11 01:06:02] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 01:06:02] [valid] Ep. 1 : Up. 1000 : ce-mean-words : 2.2404 : new best
[2023-09-11 01:06:11] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-bleu-detok.npz
[2023-09-11 01:06:12] [valid] Ep. 1 : Up. 1000 : bleu-detok : 29.2629 : new best
[2023-09-11 01:07:25] Ep. 1 : Up. 1100 : Sen. 22,232,542 : Cost 0.42706230 : Time 101.16s : 437805.26 words/s : gNorm 0.1977 : L.r. 2.0625e-05
[2023-09-11 01:08:37] Ep. 1 : Up. 1200 : Sen. 24,227,740 : Cost 0.42348987 : Time 72.39s : 608690.26 words/s : gNorm 0.1981 : L.r. 2.2500e-05
[2023-09-11 01:09:51] Ep. 1 : Up. 1300 : Sen. 26,356,719 : Cost 0.42560452 : Time 73.28s : 604304.17 words/s : gNorm 0.2061 : L.r. 2.4375e-05
[2023-09-11 01:11:05] Ep. 1 : Up. 1400 : Sen. 28,394,846 : Cost 0.42287678 : Time 74.43s : 609888.13 words/s : gNorm 0.1936 : L.r. 2.6250e-05
[2023-09-11 01:12:18] Ep. 1 : Up. 1500 : Sen. 30,442,333 : Cost 0.42398295 : Time 72.72s : 601838.98 words/s : gNorm 0.2061 : L.r. 2.8125e-05
[2023-09-11 01:12:18] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:12:18] Saving Adam parameters
[2023-09-11 01:12:19] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:12:21] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 01:12:21] [valid] Ep. 1 : Up. 1500 : perplexity : 9.37062 : new best
[2023-09-11 01:12:34] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-chrf.npz
[2023-09-11 01:12:34] [valid] Ep. 1 : Up. 1500 : chrf : 56.5788 : new best
[2023-09-11 01:12:35] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 01:12:36] [valid] Ep. 1 : Up. 1500 : ce-mean-words : 2.23758 : new best
[2023-09-11 01:12:45] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-bleu-detok.npz
[2023-09-11 01:12:45] [valid] Ep. 1 : Up. 1500 : bleu-detok : 29.3035 : new best
[2023-09-11 01:13:58] Ep. 1 : Up. 1600 : Sen. 32,372,383 : Cost 0.42146775 : Time 100.41s : 442000.34 words/s : gNorm 0.1965 : L.r. 3.0000e-05
[2023-09-11 01:15:12] Ep. 1 : Up. 1700 : Sen. 34,393,940 : Cost 0.42263454 : Time 74.12s : 603001.55 words/s : gNorm 0.2015 : L.r. 3.1875e-05
[2023-09-11 01:16:26] Ep. 1 : Up. 1800 : Sen. 36,388,353 : Cost 0.42409346 : Time 74.10s : 597651.19 words/s : gNorm 0.2082 : L.r. 3.3750e-05
[2023-09-11 01:17:39] Ep. 1 : Up. 1900 : Sen. 38,429,891 : Cost 0.42277914 : Time 72.55s : 602980.23 words/s : gNorm 0.2096 : L.r. 3.5625e-05
[2023-09-11 01:18:52] Ep. 1 : Up. 2000 : Sen. 40,480,830 : Cost 0.42296642 : Time 73.11s : 597591.66 words/s : gNorm 0.2105 : L.r. 3.7500e-05
[2023-09-11 01:18:52] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:18:53] Saving Adam parameters
[2023-09-11 01:18:53] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:18:55] [valid] Ep. 1 : Up. 2000 : perplexity : 9.37382 : stalled 1 times (last best: 9.37062)
[2023-09-11 01:19:08] [valid] Ep. 1 : Up. 2000 : chrf : 56.5645 : stalled 1 times (last best: 56.5788)
[2023-09-11 01:19:09] [valid] Ep. 1 : Up. 2000 : ce-mean-words : 2.23792 : stalled 1 times (last best: 2.23758)
[2023-09-11 01:19:19] [valid] Ep. 1 : Up. 2000 : bleu-detok : 29.2485 : stalled 1 times (last best: 29.3035)
[2023-09-11 01:20:31] Ep. 1 : Up. 2100 : Sen. 42,508,592 : Cost 0.42160124 : Time 98.94s : 447976.82 words/s : gNorm 0.2102 : L.r. 3.9375e-05
[2023-09-11 01:21:44] Ep. 1 : Up. 2200 : Sen. 44,446,794 : Cost 0.42323029 : Time 72.61s : 598092.04 words/s : gNorm 0.2153 : L.r. 4.1250e-05
[2023-09-11 01:22:56] Ep. 1 : Up. 2300 : Sen. 46,521,578 : Cost 0.42163950 : Time 72.75s : 606211.79 words/s : gNorm 0.2173 : L.r. 4.3125e-05
[2023-09-11 01:24:10] Ep. 1 : Up. 2400 : Sen. 48,611,127 : Cost 0.42312729 : Time 74.05s : 601908.91 words/s : gNorm 0.2175 : L.r. 4.5000e-05
[2023-09-11 01:25:25] Ep. 1 : Up. 2500 : Sen. 50,616,784 : Cost 0.42202282 : Time 74.39s : 608994.22 words/s : gNorm 0.2150 : L.r. 4.6875e-05
[2023-09-11 01:25:25] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:25:25] Saving Adam parameters
[2023-09-11 01:25:26] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:25:28] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 01:25:28] [valid] Ep. 1 : Up. 2500 : perplexity : 9.3359 : new best
[2023-09-11 01:25:42] [valid] Ep. 1 : Up. 2500 : chrf : 56.5788 : stalled 2 times (last best: 56.5788)
[2023-09-11 01:25:43] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 01:25:43] [valid] Ep. 1 : Up. 2500 : ce-mean-words : 2.23387 : new best
[2023-09-11 01:25:52] [valid] Ep. 1 : Up. 2500 : bleu-detok : 29.2723 : stalled 2 times (last best: 29.3035)
[2023-09-11 01:27:06] Ep. 1 : Up. 2600 : Sen. 52,665,109 : Cost 0.42341959 : Time 101.21s : 441377.74 words/s : gNorm 0.2200 : L.r. 4.8750e-05
[2023-09-11 01:28:20] Ep. 1 : Up. 2700 : Sen. 54,751,029 : Cost 0.42281470 : Time 74.07s : 605778.50 words/s : gNorm 0.2325 : L.r. 5.0625e-05
[2023-09-11 01:29:33] Ep. 1 : Up. 2800 : Sen. 56,697,833 : Cost 0.42488825 : Time 73.07s : 592207.41 words/s : gNorm 0.2340 : L.r. 5.2500e-05
[2023-09-11 01:30:46] Ep. 1 : Up. 2900 : Sen. 58,710,103 : Cost 0.42300135 : Time 72.37s : 603884.52 words/s : gNorm 0.2391 : L.r. 5.4375e-05
[2023-09-11 01:31:59] Ep. 1 : Up. 3000 : Sen. 60,731,790 : Cost 0.42334017 : Time 73.30s : 608389.92 words/s : gNorm 0.2352 : L.r. 5.6250e-05
[2023-09-11 01:31:59] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:31:59] Saving Adam parameters
[2023-09-11 01:32:00] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:32:02] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 01:32:02] [valid] Ep. 1 : Up. 3000 : perplexity : 9.32788 : new best
[2023-09-11 01:32:17] [valid] Ep. 1 : Up. 3000 : chrf : 56.5463 : stalled 3 times (last best: 56.5788)
[2023-09-11 01:32:17] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 01:32:18] [valid] Ep. 1 : Up. 3000 : ce-mean-words : 2.23301 : new best
[2023-09-11 01:32:27] [valid] Ep. 1 : Up. 3000 : bleu-detok : 29.261 : stalled 3 times (last best: 29.3035)
[2023-09-11 01:33:41] Ep. 1 : Up. 3100 : Sen. 62,814,002 : Cost 0.42631865 : Time 101.85s : 433415.18 words/s : gNorm 0.2503 : L.r. 5.8125e-05
[2023-09-11 01:34:55] Ep. 1 : Up. 3200 : Sen. 64,797,019 : Cost 0.42404962 : Time 74.02s : 603494.47 words/s : gNorm 0.2740 : L.r. 6.0000e-05
[2023-09-11 01:36:08] Ep. 1 : Up. 3300 : Sen. 66,773,097 : Cost 0.42503634 : Time 72.82s : 595798.26 words/s : gNorm 0.2474 : L.r. 6.1875e-05
[2023-09-11 01:37:20] Ep. 1 : Up. 3400 : Sen. 68,833,093 : Cost 0.42650777 : Time 72.50s : 598267.34 words/s : gNorm 0.2536 : L.r. 6.3750e-05
[2023-09-11 01:38:37] Ep. 1 : Up. 3500 : Sen. 70,871,965 : Cost 0.42652583 : Time 76.44s : 596718.85 words/s : gNorm 0.2366 : L.r. 6.5625e-05
[2023-09-11 01:38:37] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:38:37] Saving Adam parameters
[2023-09-11 01:38:37] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:38:39] [valid] Ep. 1 : Up. 3500 : perplexity : 9.4323 : stalled 1 times (last best: 9.32788)
[2023-09-11 01:38:53] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-chrf.npz
[2023-09-11 01:38:54] [valid] Ep. 1 : Up. 3500 : chrf : 56.6618 : new best
[2023-09-11 01:38:55] [valid] Ep. 1 : Up. 3500 : ce-mean-words : 2.24414 : stalled 1 times (last best: 2.23301)
[2023-09-11 01:39:04] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-bleu-detok.npz
[2023-09-11 01:39:04] [valid] Ep. 1 : Up. 3500 : bleu-detok : 29.3573 : new best
[2023-09-11 01:40:17] Ep. 1 : Up. 3600 : Sen. 72,899,705 : Cost 0.42629641 : Time 100.77s : 434667.64 words/s : gNorm 0.2747 : L.r. 6.7500e-05
[2023-09-11 01:41:30] Ep. 1 : Up. 3700 : Sen. 74,832,526 : Cost 0.42659682 : Time 72.35s : 599055.00 words/s : gNorm 0.2594 : L.r. 6.9375e-05
[2023-09-11 01:42:43] Ep. 1 : Up. 3800 : Sen. 76,787,743 : Cost 0.42606211 : Time 73.33s : 599140.37 words/s : gNorm 0.2525 : L.r. 7.1250e-05
[2023-09-11 01:43:55] Ep. 1 : Up. 3900 : Sen. 78,859,264 : Cost 0.42699769 : Time 72.48s : 600182.04 words/s : gNorm 0.2671 : L.r. 7.3125e-05
[2023-09-11 01:45:10] Ep. 1 : Up. 4000 : Sen. 80,978,709 : Cost 0.42775595 : Time 74.96s : 604410.73 words/s : gNorm 0.2469 : L.r. 7.5000e-05
[2023-09-11 01:45:10] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:45:11] Saving Adam parameters
[2023-09-11 01:45:11] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:45:13] [valid] Ep. 1 : Up. 4000 : perplexity : 9.35376 : stalled 2 times (last best: 9.32788)
[2023-09-11 01:45:27] [valid] Ep. 1 : Up. 4000 : chrf : 56.5737 : stalled 1 times (last best: 56.6618)
[2023-09-11 01:45:28] [valid] Ep. 1 : Up. 4000 : ce-mean-words : 2.23578 : stalled 2 times (last best: 2.23301)
[2023-09-11 01:45:37] [valid] Ep. 1 : Up. 4000 : bleu-detok : 29.288 : stalled 1 times (last best: 29.3573)
[2023-09-11 01:46:53] Ep. 1 : Up. 4100 : Sen. 82,981,325 : Cost 0.42928466 : Time 102.43s : 435927.11 words/s : gNorm 0.2500 : L.r. 7.6875e-05
[2023-09-11 01:48:06] Ep. 1 : Up. 4200 : Sen. 84,999,717 : Cost 0.42870831 : Time 73.52s : 600522.94 words/s : gNorm 0.2771 : L.r. 7.8750e-05
[2023-09-11 01:49:21] Ep. 1 : Up. 4300 : Sen. 87,018,110 : Cost 0.42872104 : Time 74.58s : 590972.74 words/s : gNorm 0.2667 : L.r. 8.0625e-05
[2023-09-11 01:50:34] Ep. 1 : Up. 4400 : Sen. 89,015,220 : Cost 0.42949602 : Time 73.35s : 596353.20 words/s : gNorm 0.2754 : L.r. 8.2500e-05
[2023-09-11 01:51:49] Ep. 1 : Up. 4500 : Sen. 91,035,501 : Cost 0.43040338 : Time 74.53s : 594490.93 words/s : gNorm 0.2677 : L.r. 8.4375e-05
[2023-09-11 01:51:49] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:51:49] Saving Adam parameters
[2023-09-11 01:51:50] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:51:52] [valid] Ep. 1 : Up. 4500 : perplexity : 9.42398 : stalled 3 times (last best: 9.32788)
[2023-09-11 01:52:10] [valid] Ep. 1 : Up. 4500 : chrf : 56.5394 : stalled 2 times (last best: 56.6618)
[2023-09-11 01:52:11] [valid] Ep. 1 : Up. 4500 : ce-mean-words : 2.24326 : stalled 3 times (last best: 2.23301)
[2023-09-11 01:52:20] [valid] Ep. 1 : Up. 4500 : bleu-detok : 29.2102 : stalled 2 times (last best: 29.3573)
[2023-09-11 01:53:32] Ep. 1 : Up. 4600 : Sen. 93,082,704 : Cost 0.42988995 : Time 103.65s : 428646.73 words/s : gNorm 0.2881 : L.r. 8.6250e-05
[2023-09-11 01:54:48] Ep. 1 : Up. 4700 : Sen. 95,116,183 : Cost 0.43111899 : Time 75.40s : 591226.56 words/s : gNorm 0.2760 : L.r. 8.8125e-05
[2023-09-11 01:56:01] Ep. 1 : Up. 4800 : Sen. 97,148,241 : Cost 0.43269148 : Time 73.53s : 586090.77 words/s : gNorm 0.3151 : L.r. 9.0000e-05
[2023-09-11 01:57:16] Ep. 1 : Up. 4900 : Sen. 99,112,142 : Cost 0.43132946 : Time 74.32s : 601209.31 words/s : gNorm 0.3033 : L.r. 9.1875e-05
[2023-09-11 01:58:31] Ep. 1 : Up. 5000 : Sen. 101,103,636 : Cost 0.43485913 : Time 75.15s : 583653.43 words/s : gNorm 0.3132 : L.r. 9.3750e-05
[2023-09-11 01:58:31] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 01:58:32] Saving Adam parameters
[2023-09-11 01:58:32] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 01:58:34] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 01:58:35] [valid] Ep. 1 : Up. 5000 : perplexity : 9.24899 : new best
[2023-09-11 01:58:52] [valid] Ep. 1 : Up. 5000 : chrf : 56.6403 : stalled 3 times (last best: 56.6618)
[2023-09-11 01:58:52] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 01:58:53] [valid] Ep. 1 : Up. 5000 : ce-mean-words : 2.22451 : new best
[2023-09-11 01:59:02] [valid] Ep. 1 : Up. 5000 : bleu-detok : 29.2715 : stalled 3 times (last best: 29.3573)
[2023-09-11 02:00:17] Ep. 1 : Up. 5100 : Sen. 103,154,270 : Cost 0.43177292 : Time 106.14s : 426039.12 words/s : gNorm 0.2857 : L.r. 9.5625e-05
[2023-09-11 02:01:31] Ep. 1 : Up. 5200 : Sen. 105,159,325 : Cost 0.43331209 : Time 74.33s : 584205.72 words/s : gNorm 0.3055 : L.r. 9.7500e-05
[2023-09-11 02:02:46] Ep. 1 : Up. 5300 : Sen. 107,284,045 : Cost 0.43181026 : Time 75.11s : 582902.75 words/s : gNorm 0.2991 : L.r. 9.9375e-05
[2023-09-11 02:04:02] Ep. 1 : Up. 5400 : Sen. 109,224,083 : Cost 0.43384504 : Time 75.32s : 588539.50 words/s : gNorm 0.3145 : L.r. 1.0125e-04
[2023-09-11 02:05:18] Ep. 1 : Up. 5500 : Sen. 111,295,183 : Cost 0.43385842 : Time 76.30s : 592825.18 words/s : gNorm 0.3024 : L.r. 1.0313e-04
[2023-09-11 02:05:18] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:05:19] Saving Adam parameters
[2023-09-11 02:05:19] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:05:21] [valid] Ep. 1 : Up. 5500 : perplexity : 9.3606 : stalled 1 times (last best: 9.24899)
[2023-09-11 02:05:39] [valid] Ep. 1 : Up. 5500 : chrf : 56.5076 : stalled 4 times (last best: 56.6618)
[2023-09-11 02:05:39] [valid] Ep. 1 : Up. 5500 : ce-mean-words : 2.23651 : stalled 1 times (last best: 2.22451)
[2023-09-11 02:05:49] [valid] Ep. 1 : Up. 5500 : bleu-detok : 29.1567 : stalled 4 times (last best: 29.3573)
[2023-09-11 02:07:03] Ep. 1 : Up. 5600 : Sen. 113,321,525 : Cost 0.43588015 : Time 104.58s : 420513.29 words/s : gNorm 0.3374 : L.r. 1.0500e-04
[2023-09-11 02:08:18] Ep. 1 : Up. 5700 : Sen. 115,413,794 : Cost 0.43279886 : Time 75.69s : 587461.17 words/s : gNorm 0.2974 : L.r. 1.0687e-04
[2023-09-11 02:09:32] Ep. 1 : Up. 5800 : Sen. 117,391,161 : Cost 0.43686602 : Time 73.79s : 596981.17 words/s : gNorm 0.3185 : L.r. 1.0875e-04
[2023-09-11 02:09:41] Seen 117,617,657 samples
[2023-09-11 02:09:41] Starting data epoch 2 in logical epoch 2
[2023-09-11 02:09:41] [data] Shuffling data
[2023-09-11 02:09:50] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 02:11:18] Ep. 2 : Up. 5900 : Sen. 1,759,060 : Cost 0.43529254 : Time 106.19s : 416891.41 words/s : gNorm 0.3173 : L.r. 1.1063e-04
[2023-09-11 02:12:35] Ep. 2 : Up. 6000 : Sen. 3,793,502 : Cost 0.43505535 : Time 76.37s : 585816.00 words/s : gNorm 0.3628 : L.r. 1.1250e-04
[2023-09-11 02:12:35] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:12:35] Saving Adam parameters
[2023-09-11 02:12:36] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:12:37] [valid] Ep. 2 : Up. 6000 : perplexity : 9.30435 : stalled 2 times (last best: 9.24899)
[2023-09-11 02:12:52] [valid] Ep. 2 : Up. 6000 : chrf : 56.3588 : stalled 5 times (last best: 56.6618)
[2023-09-11 02:12:53] [valid] Ep. 2 : Up. 6000 : ce-mean-words : 2.23048 : stalled 2 times (last best: 2.22451)
[2023-09-11 02:13:02] [valid] Ep. 2 : Up. 6000 : bleu-detok : 29.01 : stalled 5 times (last best: 29.3573)
[2023-09-11 02:14:17] Ep. 2 : Up. 6100 : Sen. 5,817,010 : Cost 0.43587220 : Time 102.24s : 424497.34 words/s : gNorm 0.3741 : L.r. 1.1438e-04
[2023-09-11 02:15:34] Ep. 2 : Up. 6200 : Sen. 7,846,391 : Cost 0.43628591 : Time 76.76s : 587200.75 words/s : gNorm 0.3199 : L.r. 1.1625e-04
[2023-09-11 02:16:51] Ep. 2 : Up. 6300 : Sen. 9,911,326 : Cost 0.43842334 : Time 77.24s : 581417.80 words/s : gNorm 0.3379 : L.r. 1.1813e-04
[2023-09-11 02:18:05] Ep. 2 : Up. 6400 : Sen. 11,926,230 : Cost 0.43785232 : Time 74.44s : 582614.21 words/s : gNorm 0.4041 : L.r. 1.2000e-04
[2023-09-11 02:19:22] Ep. 2 : Up. 6500 : Sen. 13,972,690 : Cost 0.43664911 : Time 76.55s : 586749.16 words/s : gNorm 0.3411 : L.r. 1.2188e-04
[2023-09-11 02:19:22] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:19:23] Saving Adam parameters
[2023-09-11 02:19:23] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:19:25] [valid] Ep. 2 : Up. 6500 : perplexity : 9.41835 : stalled 3 times (last best: 9.24899)
[2023-09-11 02:19:39] [valid] Ep. 2 : Up. 6500 : chrf : 56.5684 : stalled 6 times (last best: 56.6618)
[2023-09-11 02:19:40] [valid] Ep. 2 : Up. 6500 : ce-mean-words : 2.24266 : stalled 3 times (last best: 2.22451)
[2023-09-11 02:19:50] [valid] Ep. 2 : Up. 6500 : bleu-detok : 29.2192 : stalled 6 times (last best: 29.3573)
[2023-09-11 02:21:06] Ep. 2 : Up. 6600 : Sen. 15,999,950 : Cost 0.44089934 : Time 103.88s : 429050.20 words/s : gNorm 0.3799 : L.r. 1.2375e-04
[2023-09-11 02:22:22] Ep. 2 : Up. 6700 : Sen. 18,006,988 : Cost 0.43976825 : Time 76.08s : 581273.13 words/s : gNorm 0.3497 : L.r. 1.2562e-04
[2023-09-11 02:23:38] Ep. 2 : Up. 6800 : Sen. 20,050,151 : Cost 0.43943217 : Time 75.77s : 582056.26 words/s : gNorm 0.3594 : L.r. 1.2750e-04
[2023-09-11 02:24:54] Ep. 2 : Up. 6900 : Sen. 22,084,756 : Cost 0.43961427 : Time 76.36s : 585126.16 words/s : gNorm 0.3427 : L.r. 1.2938e-04
[2023-09-11 02:26:10] Ep. 2 : Up. 7000 : Sen. 24,084,997 : Cost 0.43950185 : Time 75.83s : 583140.96 words/s : gNorm 0.3508 : L.r. 1.3125e-04
[2023-09-11 02:26:10] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:26:10] Saving Adam parameters
[2023-09-11 02:26:11] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:26:13] [valid] Ep. 2 : Up. 7000 : perplexity : 9.51477 : stalled 4 times (last best: 9.24899)
[2023-09-11 02:26:33] [valid] Ep. 2 : Up. 7000 : chrf : 56.5243 : stalled 7 times (last best: 56.6618)
[2023-09-11 02:26:34] [valid] Ep. 2 : Up. 7000 : ce-mean-words : 2.25285 : stalled 4 times (last best: 2.22451)
[2023-09-11 02:26:44] [valid] Ep. 2 : Up. 7000 : bleu-detok : 28.998 : stalled 7 times (last best: 29.3573)
[2023-09-11 02:27:58] Ep. 2 : Up. 7100 : Sen. 26,087,338 : Cost 0.44170338 : Time 107.98s : 406419.42 words/s : gNorm 0.3440 : L.r. 1.3313e-04
[2023-09-11 02:29:13] Ep. 2 : Up. 7200 : Sen. 28,135,428 : Cost 0.44162363 : Time 75.54s : 578628.76 words/s : gNorm 0.3666 : L.r. 1.3500e-04
[2023-09-11 02:30:30] Ep. 2 : Up. 7300 : Sen. 30,179,637 : Cost 0.44242415 : Time 77.01s : 580615.65 words/s : gNorm 0.3686 : L.r. 1.3688e-04
[2023-09-11 02:31:45] Ep. 2 : Up. 7400 : Sen. 32,111,469 : Cost 0.44329870 : Time 74.08s : 578951.92 words/s : gNorm 0.4167 : L.r. 1.3875e-04
[2023-09-11 02:33:01] Ep. 2 : Up. 7500 : Sen. 34,178,837 : Cost 0.44330108 : Time 76.84s : 582295.75 words/s : gNorm 0.3482 : L.r. 1.4063e-04
[2023-09-11 02:33:01] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:33:02] Saving Adam parameters
[2023-09-11 02:33:02] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:33:04] [valid] Ep. 2 : Up. 7500 : perplexity : 9.64654 : stalled 5 times (last best: 9.24899)
[2023-09-11 02:33:24] [valid] Ep. 2 : Up. 7500 : chrf : 56.353 : stalled 8 times (last best: 56.6618)
[2023-09-11 02:33:25] [valid] Ep. 2 : Up. 7500 : ce-mean-words : 2.2666 : stalled 5 times (last best: 2.22451)
[2023-09-11 02:33:34] [valid] Ep. 2 : Up. 7500 : bleu-detok : 28.9778 : stalled 8 times (last best: 29.3573)
[2023-09-11 02:34:47] Ep. 2 : Up. 7600 : Sen. 36,229,331 : Cost 0.44393086 : Time 105.48s : 411116.48 words/s : gNorm 0.3554 : L.r. 1.4250e-04
[2023-09-11 02:36:03] Ep. 2 : Up. 7700 : Sen. 38,199,675 : Cost 0.44434705 : Time 76.49s : 578888.46 words/s : gNorm 0.3605 : L.r. 1.4438e-04
[2023-09-11 02:37:20] Ep. 2 : Up. 7800 : Sen. 40,259,349 : Cost 0.44409201 : Time 76.86s : 581931.44 words/s : gNorm 0.3679 : L.r. 1.4625e-04
[2023-09-11 02:38:36] Ep. 2 : Up. 7900 : Sen. 42,260,642 : Cost 0.44195700 : Time 75.92s : 583178.74 words/s : gNorm 0.3653 : L.r. 1.4813e-04
[2023-09-11 02:39:51] Ep. 2 : Up. 8000 : Sen. 44,275,879 : Cost 0.45018107 : Time 74.88s : 579747.29 words/s : gNorm 0.3928 : L.r. 1.5000e-04
[2023-09-11 02:39:51] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:39:52] Saving Adam parameters
[2023-09-11 02:39:52] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:39:54] [valid] Ep. 2 : Up. 8000 : perplexity : 9.33703 : stalled 6 times (last best: 9.24899)
[2023-09-11 02:40:13] [valid] Ep. 2 : Up. 8000 : chrf : 56.3478 : stalled 9 times (last best: 56.6618)
[2023-09-11 02:40:13] [valid] Ep. 2 : Up. 8000 : ce-mean-words : 2.23399 : stalled 6 times (last best: 2.22451)
[2023-09-11 02:40:23] [valid] Ep. 2 : Up. 8000 : bleu-detok : 28.9121 : stalled 9 times (last best: 29.3573)
[2023-09-11 02:41:38] Ep. 2 : Up. 8100 : Sen. 46,254,985 : Cost 0.44577724 : Time 106.94s : 417302.57 words/s : gNorm 0.3770 : L.r. 1.5188e-04
[2023-09-11 02:42:53] Ep. 2 : Up. 8200 : Sen. 48,304,421 : Cost 0.44609118 : Time 75.44s : 585282.25 words/s : gNorm 0.4433 : L.r. 1.5375e-04
[2023-09-11 02:44:09] Ep. 2 : Up. 8300 : Sen. 50,287,261 : Cost 0.44771793 : Time 75.85s : 580812.20 words/s : gNorm 0.4062 : L.r. 1.5563e-04
[2023-09-11 02:45:26] Ep. 2 : Up. 8400 : Sen. 52,320,170 : Cost 0.44723606 : Time 76.87s : 585065.01 words/s : gNorm 0.3877 : L.r. 1.5750e-04
[2023-09-11 02:46:41] Ep. 2 : Up. 8500 : Sen. 54,412,165 : Cost 0.45229584 : Time 74.52s : 577499.29 words/s : gNorm 0.4185 : L.r. 1.5938e-04
[2023-09-11 02:46:41] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:46:41] Saving Adam parameters
[2023-09-11 02:46:42] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:46:44] [valid] Ep. 2 : Up. 8500 : perplexity : 9.46526 : stalled 7 times (last best: 9.24899)
[2023-09-11 02:47:01] [valid] Ep. 2 : Up. 8500 : chrf : 56.4991 : stalled 10 times (last best: 56.6618)
[2023-09-11 02:47:02] [valid] Ep. 2 : Up. 8500 : ce-mean-words : 2.24763 : stalled 7 times (last best: 2.22451)
[2023-09-11 02:47:12] [valid] Ep. 2 : Up. 8500 : bleu-detok : 29.0003 : stalled 10 times (last best: 29.3573)
[2023-09-11 02:48:27] Ep. 2 : Up. 8600 : Sen. 56,361,675 : Cost 0.44640896 : Time 105.94s : 419720.90 words/s : gNorm 0.3808 : L.r. 1.6125e-04
[2023-09-11 02:49:42] Ep. 2 : Up. 8700 : Sen. 58,368,646 : Cost 0.45123610 : Time 75.49s : 580507.10 words/s : gNorm 0.4020 : L.r. 1.6313e-04
[2023-09-11 02:50:59] Ep. 2 : Up. 8800 : Sen. 60,390,401 : Cost 0.44908383 : Time 76.66s : 584864.57 words/s : gNorm 0.3837 : L.r. 1.6500e-04
[2023-09-11 02:52:14] Ep. 2 : Up. 8900 : Sen. 62,456,131 : Cost 0.45019126 : Time 75.68s : 577331.51 words/s : gNorm 0.3968 : L.r. 1.6688e-04
[2023-09-11 02:53:30] Ep. 2 : Up. 9000 : Sen. 64,479,410 : Cost 0.45145935 : Time 75.33s : 582451.90 words/s : gNorm 0.4086 : L.r. 1.6875e-04
[2023-09-11 02:53:30] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 02:53:30] Saving Adam parameters
[2023-09-11 02:53:31] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 02:53:33] [valid] Ep. 2 : Up. 9000 : perplexity : 9.37685 : stalled 8 times (last best: 9.24899)
[2023-09-11 02:53:49] [valid] Ep. 2 : Up. 9000 : chrf : 56.2681 : stalled 11 times (last best: 56.6618)
[2023-09-11 02:53:50] [valid] Ep. 2 : Up. 9000 : ce-mean-words : 2.23824 : stalled 8 times (last best: 2.22451)
[2023-09-11 02:54:00] [valid] Ep. 2 : Up. 9000 : bleu-detok : 28.9621 : stalled 11 times (last best: 29.3573)
[2023-09-11 02:55:15] Ep. 2 : Up. 9100 : Sen. 66,479,815 : Cost 0.45879593 : Time 105.16s : 423269.50 words/s : gNorm 0.4866 : L.r. 1.7063e-04
[2023-09-11 02:56:31] Ep. 2 : Up. 9200 : Sen. 68,546,239 : Cost 0.45201558 : Time 76.35s : 584531.65 words/s : gNorm 0.3865 : L.r. 1.7250e-04
[2023-09-11 02:57:49] Ep. 2 : Up. 9300 : Sen. 70,643,337 : Cost 0.45301008 : Time 77.44s : 577800.46 words/s : gNorm 0.4138 : L.r. 1.7438e-04
[2023-09-11 02:59:05] Ep. 2 : Up. 9400 : Sen. 72,590,253 : Cost 0.45366746 : Time 75.85s : 587144.93 words/s : gNorm 0.3965 : L.r. 1.7625e-04
[2023-09-11 03:00:21] Ep. 2 : Up. 9500 : Sen. 74,591,158 : Cost 0.45370144 : Time 76.10s : 584992.80 words/s : gNorm 0.4483 : L.r. 1.7813e-04
[2023-09-11 03:00:21] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:00:21] Saving Adam parameters
[2023-09-11 03:00:22] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:00:23] [valid] Ep. 2 : Up. 9500 : perplexity : 9.51243 : stalled 9 times (last best: 9.24899)
[2023-09-11 03:00:39] [valid] Ep. 2 : Up. 9500 : chrf : 56.3308 : stalled 12 times (last best: 56.6618)
[2023-09-11 03:00:40] [valid] Ep. 2 : Up. 9500 : ce-mean-words : 2.2526 : stalled 9 times (last best: 2.22451)
[2023-09-11 03:00:49] [valid] Ep. 2 : Up. 9500 : bleu-detok : 28.9965 : stalled 12 times (last best: 29.3573)
[2023-09-11 03:02:05] Ep. 2 : Up. 9600 : Sen. 76,715,472 : Cost 0.45129025 : Time 104.23s : 423844.94 words/s : gNorm 0.3917 : L.r. 1.8000e-04
[2023-09-11 03:03:21] Ep. 2 : Up. 9700 : Sen. 78,675,644 : Cost 0.45458451 : Time 76.52s : 589839.64 words/s : gNorm 0.4244 : L.r. 1.8188e-04
[2023-09-11 03:04:38] Ep. 2 : Up. 9800 : Sen. 80,738,999 : Cost 0.45216843 : Time 76.26s : 579181.32 words/s : gNorm 0.3907 : L.r. 1.8375e-04
[2023-09-11 03:05:55] Ep. 2 : Up. 9900 : Sen. 82,775,047 : Cost 0.45305732 : Time 77.05s : 581495.03 words/s : gNorm 0.4023 : L.r. 1.8563e-04
[2023-09-11 03:07:10] Ep. 2 : Up. 10000 : Sen. 84,843,466 : Cost 0.45518455 : Time 75.74s : 581560.29 words/s : gNorm 0.4078 : L.r. 1.8750e-04
[2023-09-11 03:07:10] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:07:11] Saving Adam parameters
[2023-09-11 03:07:11] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:07:13] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 03:07:13] [valid] Ep. 2 : Up. 10000 : perplexity : 9.22822 : new best
[2023-09-11 03:07:28] [valid] Ep. 2 : Up. 10000 : chrf : 56.4188 : stalled 13 times (last best: 56.6618)
[2023-09-11 03:07:29] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 03:07:29] [valid] Ep. 2 : Up. 10000 : ce-mean-words : 2.22227 : new best
[2023-09-11 03:07:39] [valid] Ep. 2 : Up. 10000 : bleu-detok : 29.1601 : stalled 13 times (last best: 29.3573)
[2023-09-11 03:08:56] Ep. 2 : Up. 10100 : Sen. 86,907,910 : Cost 0.45677298 : Time 105.70s : 425702.18 words/s : gNorm 0.4084 : L.r. 1.8938e-04
[2023-09-11 03:10:12] Ep. 2 : Up. 10200 : Sen. 88,918,335 : Cost 0.46012917 : Time 75.50s : 580249.41 words/s : gNorm 0.4314 : L.r. 1.9125e-04
[2023-09-11 03:11:27] Ep. 2 : Up. 10300 : Sen. 90,883,750 : Cost 0.45785868 : Time 75.80s : 579047.49 words/s : gNorm 0.4459 : L.r. 1.9313e-04
[2023-09-11 03:12:44] Ep. 2 : Up. 10400 : Sen. 92,972,840 : Cost 0.45930928 : Time 76.56s : 584945.36 words/s : gNorm 0.4518 : L.r. 1.9500e-04
[2023-09-11 03:14:00] Ep. 2 : Up. 10500 : Sen. 94,990,336 : Cost 0.45713091 : Time 76.06s : 582565.55 words/s : gNorm 0.4192 : L.r. 1.9688e-04
[2023-09-11 03:14:00] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:14:01] Saving Adam parameters
[2023-09-11 03:14:01] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:14:03] [valid] Ep. 2 : Up. 10500 : perplexity : 9.27049 : stalled 1 times (last best: 9.22822)
[2023-09-11 03:14:18] [valid] Ep. 2 : Up. 10500 : chrf : 56.354 : stalled 14 times (last best: 56.6618)
[2023-09-11 03:14:18] [valid] Ep. 2 : Up. 10500 : ce-mean-words : 2.22684 : stalled 1 times (last best: 2.22227)
[2023-09-11 03:14:28] [valid] Ep. 2 : Up. 10500 : bleu-detok : 29.0794 : stalled 14 times (last best: 29.3573)
[2023-09-11 03:15:43] Ep. 2 : Up. 10600 : Sen. 96,955,642 : Cost 0.45435300 : Time 102.61s : 420785.72 words/s : gNorm 0.4133 : L.r. 1.9875e-04
[2023-09-11 03:16:58] Ep. 2 : Up. 10700 : Sen. 98,969,314 : Cost 0.45708016 : Time 75.30s : 585647.33 words/s : gNorm 0.4092 : L.r. 2.0062e-04
[2023-09-11 03:18:14] Ep. 2 : Up. 10800 : Sen. 101,013,066 : Cost 0.45888111 : Time 76.46s : 583534.56 words/s : gNorm 0.4177 : L.r. 2.0250e-04
[2023-09-11 03:19:31] Ep. 2 : Up. 10900 : Sen. 103,050,464 : Cost 0.45468414 : Time 76.57s : 576351.55 words/s : gNorm 0.4170 : L.r. 2.0437e-04
[2023-09-11 03:20:46] Ep. 2 : Up. 11000 : Sen. 105,041,454 : Cost 0.46108475 : Time 75.50s : 580819.64 words/s : gNorm 0.4326 : L.r. 2.0625e-04
[2023-09-11 03:20:46] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:20:47] Saving Adam parameters
[2023-09-11 03:20:48] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:20:50] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 03:20:50] [valid] Ep. 2 : Up. 11000 : perplexity : 9.14892 : new best
[2023-09-11 03:21:11] [valid] Ep. 2 : Up. 11000 : chrf : 56.2931 : stalled 15 times (last best: 56.6618)
[2023-09-11 03:21:12] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 03:21:12] [valid] Ep. 2 : Up. 11000 : ce-mean-words : 2.21364 : new best
[2023-09-11 03:21:22] [valid] Ep. 2 : Up. 11000 : bleu-detok : 28.9172 : stalled 15 times (last best: 29.3573)
[2023-09-11 03:22:33] Ep. 2 : Up. 11100 : Sen. 107,010,069 : Cost 0.46091339 : Time 106.86s : 402902.42 words/s : gNorm 0.4309 : L.r. 2.0813e-04
[2023-09-11 03:23:49] Ep. 2 : Up. 11200 : Sen. 109,047,432 : Cost 0.45988846 : Time 75.80s : 582882.59 words/s : gNorm 0.4370 : L.r. 2.1000e-04
[2023-09-11 03:25:04] Ep. 2 : Up. 11300 : Sen. 111,057,831 : Cost 0.46027207 : Time 74.82s : 583328.64 words/s : gNorm 0.4479 : L.r. 2.1188e-04
[2023-09-11 03:26:22] Ep. 2 : Up. 11400 : Sen. 113,071,514 : Cost 0.46048781 : Time 78.03s : 578308.26 words/s : gNorm 0.4477 : L.r. 2.1375e-04
[2023-09-11 03:27:38] Ep. 2 : Up. 11500 : Sen. 115,197,748 : Cost 0.46182981 : Time 76.42s : 585154.30 words/s : gNorm 0.4314 : L.r. 2.1563e-04
[2023-09-11 03:27:38] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:27:39] Saving Adam parameters
[2023-09-11 03:27:40] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:27:42] [valid] Ep. 2 : Up. 11500 : perplexity : 9.29636 : stalled 1 times (last best: 9.14892)
[2023-09-11 03:28:01] [valid] Ep. 2 : Up. 11500 : chrf : 55.8254 : stalled 16 times (last best: 56.6618)
[2023-09-11 03:28:02] [valid] Ep. 2 : Up. 11500 : ce-mean-words : 2.22962 : stalled 1 times (last best: 2.21364)
[2023-09-11 03:28:12] [valid] Ep. 2 : Up. 11500 : bleu-detok : 28.6646 : stalled 16 times (last best: 29.3573)
[2023-09-11 03:29:26] Ep. 2 : Up. 11600 : Sen. 117,173,558 : Cost 0.46155766 : Time 107.09s : 423447.31 words/s : gNorm 0.4168 : L.r. 2.1750e-04
[2023-09-11 03:29:40] Seen 117,617,657 samples
[2023-09-11 03:29:40] Starting data epoch 3 in logical epoch 3
[2023-09-11 03:29:40] [data] Shuffling data
[2023-09-11 03:29:48] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 03:31:12] Ep. 3 : Up. 11700 : Sen. 1,671,609 : Cost 0.45964742 : Time 106.52s : 416334.51 words/s : gNorm 0.4468 : L.r. 2.1938e-04
[2023-09-11 03:32:28] Ep. 3 : Up. 11800 : Sen. 3,653,504 : Cost 0.46393234 : Time 76.09s : 582960.87 words/s : gNorm 0.4803 : L.r. 2.2125e-04
[2023-09-11 03:33:44] Ep. 3 : Up. 11900 : Sen. 5,698,176 : Cost 0.46153855 : Time 76.11s : 584973.99 words/s : gNorm 0.4442 : L.r. 2.2312e-04
[2023-09-11 03:34:58] Ep. 3 : Up. 12000 : Sen. 7,727,909 : Cost 0.47250891 : Time 73.63s : 576527.28 words/s : gNorm 0.4762 : L.r. 2.2500e-04
[2023-09-11 03:34:58] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:34:59] Saving Adam parameters
[2023-09-11 03:34:59] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:35:01] [valid] Ep. 3 : Up. 12000 : perplexity : 9.40242 : stalled 2 times (last best: 9.14892)
[2023-09-11 03:35:15] [valid] Ep. 3 : Up. 12000 : chrf : 56.2097 : stalled 17 times (last best: 56.6618)
[2023-09-11 03:35:16] [valid] Ep. 3 : Up. 12000 : ce-mean-words : 2.24097 : stalled 2 times (last best: 2.21364)
[2023-09-11 03:35:26] [valid] Ep. 3 : Up. 12000 : bleu-detok : 28.8862 : stalled 17 times (last best: 29.3573)
[2023-09-11 03:36:41] Ep. 3 : Up. 12100 : Sen. 9,717,101 : Cost 0.45884091 : Time 103.07s : 435746.93 words/s : gNorm 0.4207 : L.r. 2.2688e-04
[2023-09-11 03:37:57] Ep. 3 : Up. 12200 : Sen. 11,709,810 : Cost 0.46756554 : Time 75.70s : 580201.81 words/s : gNorm 0.4524 : L.r. 2.2875e-04
[2023-09-11 03:39:12] Ep. 3 : Up. 12300 : Sen. 13,629,920 : Cost 0.45817339 : Time 74.93s : 584348.03 words/s : gNorm 0.4205 : L.r. 2.3063e-04
[2023-09-11 03:40:28] Ep. 3 : Up. 12400 : Sen. 15,712,911 : Cost 0.46949366 : Time 76.01s : 582989.77 words/s : gNorm 0.4378 : L.r. 2.3250e-04
[2023-09-11 03:41:43] Ep. 3 : Up. 12500 : Sen. 17,800,160 : Cost 0.46521175 : Time 75.63s : 581631.50 words/s : gNorm 0.4864 : L.r. 2.3438e-04
[2023-09-11 03:41:43] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:41:44] Saving Adam parameters
[2023-09-11 03:41:44] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:41:46] [valid] Ep. 3 : Up. 12500 : perplexity : 9.57626 : stalled 3 times (last best: 9.14892)
[2023-09-11 03:42:01] [valid] Ep. 3 : Up. 12500 : chrf : 56.2395 : stalled 18 times (last best: 56.6618)
[2023-09-11 03:42:01] [valid] Ep. 3 : Up. 12500 : ce-mean-words : 2.25929 : stalled 3 times (last best: 2.21364)
[2023-09-11 03:42:11] [valid] Ep. 3 : Up. 12500 : bleu-detok : 28.7866 : stalled 18 times (last best: 29.3573)
[2023-09-11 03:43:27] Ep. 3 : Up. 12600 : Sen. 19,855,500 : Cost 0.47429937 : Time 103.47s : 427974.53 words/s : gNorm 0.5133 : L.r. 2.3625e-04
[2023-09-11 03:44:42] Ep. 3 : Up. 12700 : Sen. 21,813,808 : Cost 0.46300033 : Time 75.68s : 582535.54 words/s : gNorm 0.4308 : L.r. 2.3813e-04
[2023-09-11 03:45:59] Ep. 3 : Up. 12800 : Sen. 23,797,319 : Cost 0.46415454 : Time 76.26s : 584581.66 words/s : gNorm 0.4007 : L.r. 2.4000e-04
[2023-09-11 03:47:15] Ep. 3 : Up. 12900 : Sen. 25,841,592 : Cost 0.46727765 : Time 76.49s : 583076.99 words/s : gNorm 0.4215 : L.r. 2.4188e-04
[2023-09-11 03:48:31] Ep. 3 : Up. 13000 : Sen. 27,873,942 : Cost 0.46824524 : Time 75.51s : 576615.67 words/s : gNorm 0.4561 : L.r. 2.4375e-04
[2023-09-11 03:48:31] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:48:31] Saving Adam parameters
[2023-09-11 03:48:31] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:48:33] [valid] Ep. 3 : Up. 13000 : perplexity : 9.318 : stalled 4 times (last best: 9.14892)
[2023-09-11 03:48:48] [valid] Ep. 3 : Up. 13000 : chrf : 56.2765 : stalled 19 times (last best: 56.6618)
[2023-09-11 03:48:49] [valid] Ep. 3 : Up. 13000 : ce-mean-words : 2.23195 : stalled 4 times (last best: 2.21364)
[2023-09-11 03:48:59] [valid] Ep. 3 : Up. 13000 : bleu-detok : 28.9013 : stalled 19 times (last best: 29.3573)
[2023-09-11 03:50:15] Ep. 3 : Up. 13100 : Sen. 29,912,452 : Cost 0.46578091 : Time 104.79s : 428318.34 words/s : gNorm 0.5091 : L.r. 2.4563e-04
[2023-09-11 03:51:32] Ep. 3 : Up. 13200 : Sen. 31,965,701 : Cost 0.47173670 : Time 76.51s : 581037.29 words/s : gNorm 0.4398 : L.r. 2.4750e-04
[2023-09-11 03:52:48] Ep. 3 : Up. 13300 : Sen. 33,974,950 : Cost 0.46848965 : Time 75.64s : 585932.89 words/s : gNorm 0.4986 : L.r. 2.4938e-04
[2023-09-11 03:54:03] Ep. 3 : Up. 13400 : Sen. 35,988,125 : Cost 0.46739930 : Time 75.79s : 575556.95 words/s : gNorm 0.4796 : L.r. 2.5125e-04
[2023-09-11 03:55:21] Ep. 3 : Up. 13500 : Sen. 38,040,025 : Cost 0.46769854 : Time 77.39s : 583679.24 words/s : gNorm 0.4217 : L.r. 2.5313e-04
[2023-09-11 03:55:21] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 03:55:21] Saving Adam parameters
[2023-09-11 03:55:22] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 03:55:24] [valid] Ep. 3 : Up. 13500 : perplexity : 9.52013 : stalled 5 times (last best: 9.14892)
[2023-09-11 03:55:45] [valid] Ep. 3 : Up. 13500 : chrf : 56.2621 : stalled 20 times (last best: 56.6618)
[2023-09-11 03:55:45] [valid] Ep. 3 : Up. 13500 : ce-mean-words : 2.25341 : stalled 5 times (last best: 2.21364)
[2023-09-11 03:55:55] [valid] Ep. 3 : Up. 13500 : bleu-detok : 28.817 : stalled 20 times (last best: 29.3573)
[2023-09-11 03:57:09] Ep. 3 : Up. 13600 : Sen. 40,087,938 : Cost 0.47603253 : Time 108.23s : 413726.94 words/s : gNorm 0.4919 : L.r. 2.5500e-04
[2023-09-11 03:58:25] Ep. 3 : Up. 13700 : Sen. 42,099,953 : Cost 0.46771187 : Time 75.54s : 581784.00 words/s : gNorm 0.4588 : L.r. 2.5688e-04
[2023-09-11 03:59:41] Ep. 3 : Up. 13800 : Sen. 44,113,058 : Cost 0.46890762 : Time 76.63s : 577664.25 words/s : gNorm 0.4328 : L.r. 2.5875e-04
[2023-09-11 04:00:56] Ep. 3 : Up. 13900 : Sen. 46,139,173 : Cost 0.48387015 : Time 74.98s : 584302.46 words/s : gNorm 0.4631 : L.r. 2.6063e-04
[2023-09-11 04:02:13] Ep. 3 : Up. 14000 : Sen. 48,129,537 : Cost 0.46535188 : Time 76.59s : 581935.60 words/s : gNorm 0.4233 : L.r. 2.6250e-04
[2023-09-11 04:02:13] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:02:13] Saving Adam parameters
[2023-09-11 04:02:14] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:02:16] [valid] Ep. 3 : Up. 14000 : perplexity : 9.33328 : stalled 6 times (last best: 9.14892)
[2023-09-11 04:02:35] [valid] Ep. 3 : Up. 14000 : chrf : 56.271 : stalled 21 times (last best: 56.6618)
[2023-09-11 04:02:36] [valid] Ep. 3 : Up. 14000 : ce-mean-words : 2.23359 : stalled 6 times (last best: 2.21364)
[2023-09-11 04:02:45] [valid] Ep. 3 : Up. 14000 : bleu-detok : 29.0086 : stalled 21 times (last best: 29.3573)
[2023-09-11 04:03:59] Ep. 3 : Up. 14100 : Sen. 50,143,182 : Cost 0.47033134 : Time 105.94s : 415345.01 words/s : gNorm 0.4536 : L.r. 2.6438e-04
[2023-09-11 04:05:14] Ep. 3 : Up. 14200 : Sen. 52,158,574 : Cost 0.47534651 : Time 75.07s : 580570.00 words/s : gNorm 0.4307 : L.r. 2.6625e-04
[2023-09-11 04:06:29] Ep. 3 : Up. 14300 : Sen. 54,179,021 : Cost 0.47154137 : Time 74.95s : 574895.05 words/s : gNorm 0.4565 : L.r. 2.6813e-04
[2023-09-11 04:07:45] Ep. 3 : Up. 14400 : Sen. 56,179,259 : Cost 0.46831015 : Time 76.74s : 591462.13 words/s : gNorm 0.3965 : L.r. 2.7000e-04
[2023-09-11 04:09:01] Ep. 3 : Up. 14500 : Sen. 58,235,967 : Cost 0.47158495 : Time 75.35s : 579913.63 words/s : gNorm 0.4274 : L.r. 2.7188e-04
[2023-09-11 04:09:01] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:09:01] Saving Adam parameters
[2023-09-11 04:09:02] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:09:04] [valid] Ep. 3 : Up. 14500 : perplexity : 9.34278 : stalled 7 times (last best: 9.14892)
[2023-09-11 04:09:23] [valid] Ep. 3 : Up. 14500 : chrf : 56.2104 : stalled 22 times (last best: 56.6618)
[2023-09-11 04:09:24] [valid] Ep. 3 : Up. 14500 : ce-mean-words : 2.2346 : stalled 7 times (last best: 2.21364)
[2023-09-11 04:09:33] [valid] Ep. 3 : Up. 14500 : bleu-detok : 28.6602 : stalled 22 times (last best: 29.3573)
[2023-09-11 04:10:48] Ep. 3 : Up. 14600 : Sen. 60,208,386 : Cost 0.48044720 : Time 106.99s : 410852.68 words/s : gNorm 0.4894 : L.r. 2.7375e-04
[2023-09-11 04:12:03] Ep. 3 : Up. 14700 : Sen. 62,338,711 : Cost 0.46734679 : Time 75.56s : 580911.73 words/s : gNorm 0.4083 : L.r. 2.7563e-04
[2023-09-11 04:13:19] Ep. 3 : Up. 14800 : Sen. 64,254,309 : Cost 0.47762144 : Time 75.25s : 590008.00 words/s : gNorm 0.4400 : L.r. 2.7750e-04
[2023-09-11 04:14:36] Ep. 3 : Up. 14900 : Sen. 66,360,700 : Cost 0.47268590 : Time 77.13s : 578426.39 words/s : gNorm 0.4305 : L.r. 2.7938e-04
[2023-09-11 04:15:51] Ep. 3 : Up. 15000 : Sen. 68,293,053 : Cost 0.47462302 : Time 75.35s : 581211.45 words/s : gNorm 0.4436 : L.r. 2.8125e-04
[2023-09-11 04:15:51] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:15:52] Saving Adam parameters
[2023-09-11 04:15:52] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:15:54] [valid] Ep. 3 : Up. 15000 : perplexity : 9.15696 : stalled 8 times (last best: 9.14892)
[2023-09-11 04:16:12] [valid] Ep. 3 : Up. 15000 : chrf : 56.2248 : stalled 23 times (last best: 56.6618)
[2023-09-11 04:16:13] [valid] Ep. 3 : Up. 15000 : ce-mean-words : 2.21451 : stalled 8 times (last best: 2.21364)
[2023-09-11 04:16:22] [valid] Ep. 3 : Up. 15000 : bleu-detok : 28.8902 : stalled 23 times (last best: 29.3573)
[2023-09-11 04:17:36] Ep. 3 : Up. 15100 : Sen. 70,368,915 : Cost 0.47612333 : Time 104.59s : 415710.84 words/s : gNorm 0.4889 : L.r. 2.8313e-04
[2023-09-11 04:18:51] Ep. 3 : Up. 15200 : Sen. 72,299,456 : Cost 0.47654164 : Time 75.51s : 583900.81 words/s : gNorm 0.4822 : L.r. 2.8500e-04
[2023-09-11 04:20:07] Ep. 3 : Up. 15300 : Sen. 74,329,510 : Cost 0.46934593 : Time 75.66s : 578013.70 words/s : gNorm 0.4430 : L.r. 2.8688e-04
[2023-09-11 04:21:24] Ep. 3 : Up. 15400 : Sen. 76,414,468 : Cost 0.46952039 : Time 77.62s : 584847.54 words/s : gNorm 0.3987 : L.r. 2.8875e-04
[2023-09-11 04:22:42] Ep. 3 : Up. 15500 : Sen. 78,501,375 : Cost 0.48149359 : Time 77.31s : 572085.50 words/s : gNorm 0.4704 : L.r. 2.9063e-04
[2023-09-11 04:22:42] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:22:42] Saving Adam parameters
[2023-09-11 04:22:43] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:22:45] [valid] Ep. 3 : Up. 15500 : perplexity : 9.62813 : stalled 9 times (last best: 9.14892)
[2023-09-11 04:23:02] [valid] Ep. 3 : Up. 15500 : chrf : 56.1592 : stalled 24 times (last best: 56.6618)
[2023-09-11 04:23:02] [valid] Ep. 3 : Up. 15500 : ce-mean-words : 2.26469 : stalled 9 times (last best: 2.21364)
[2023-09-11 04:23:12] [valid] Ep. 3 : Up. 15500 : bleu-detok : 28.5019 : stalled 24 times (last best: 29.3573)
[2023-09-11 04:24:26] Ep. 3 : Up. 15600 : Sen. 80,462,406 : Cost 0.46997869 : Time 104.51s : 421935.12 words/s : gNorm 0.4147 : L.r. 2.9250e-04
[2023-09-11 04:25:43] Ep. 3 : Up. 15700 : Sen. 82,517,031 : Cost 0.47373977 : Time 77.02s : 582248.19 words/s : gNorm 0.4226 : L.r. 2.9438e-04
[2023-09-11 04:27:01] Ep. 3 : Up. 15800 : Sen. 84,594,197 : Cost 0.48098871 : Time 77.81s : 579768.34 words/s : gNorm 0.4195 : L.r. 2.9625e-04
[2023-09-11 04:28:17] Ep. 3 : Up. 15900 : Sen. 86,572,298 : Cost 0.47653070 : Time 75.78s : 578139.52 words/s : gNorm 0.4516 : L.r. 2.9812e-04
[2023-09-11 04:29:32] Ep. 3 : Up. 16000 : Sen. 88,596,982 : Cost 0.47467619 : Time 75.40s : 583457.22 words/s : gNorm 0.4336 : L.r. 3.0000e-04
[2023-09-11 04:29:32] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:29:33] Saving Adam parameters
[2023-09-11 04:29:33] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:29:35] [valid] Ep. 3 : Up. 16000 : perplexity : 9.5513 : stalled 10 times (last best: 9.14892)
[2023-09-11 04:29:51] [valid] Ep. 3 : Up. 16000 : chrf : 56.3754 : stalled 25 times (last best: 56.6618)
[2023-09-11 04:29:52] [valid] Ep. 3 : Up. 16000 : ce-mean-words : 2.25668 : stalled 10 times (last best: 2.21364)
[2023-09-11 04:30:02] [valid] Ep. 3 : Up. 16000 : bleu-detok : 28.8131 : stalled 25 times (last best: 29.3573)
[2023-09-11 04:31:17] Ep. 3 : Up. 16100 : Sen. 90,731,794 : Cost 0.47113079 : Time 105.04s : 425719.06 words/s : gNorm 0.3926 : L.r. 3.0000e-04
[2023-09-11 04:32:33] Ep. 3 : Up. 16200 : Sen. 92,610,834 : Cost 0.48181129 : Time 75.59s : 581579.48 words/s : gNorm 0.4852 : L.r. 3.0000e-04
[2023-09-11 04:33:50] Ep. 3 : Up. 16300 : Sen. 94,719,324 : Cost 0.47987059 : Time 77.32s : 583982.64 words/s : gNorm 0.4526 : L.r. 3.0000e-04
[2023-09-11 04:35:06] Ep. 3 : Up. 16400 : Sen. 96,765,484 : Cost 0.47987270 : Time 75.87s : 589372.74 words/s : gNorm 0.4206 : L.r. 3.0000e-04
[2023-09-11 04:36:24] Ep. 3 : Up. 16500 : Sen. 98,902,774 : Cost 0.47636414 : Time 77.57s : 580060.92 words/s : gNorm 0.4195 : L.r. 3.0000e-04
[2023-09-11 04:36:24] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:36:24] Saving Adam parameters
[2023-09-11 04:36:25] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:36:26] [valid] Ep. 3 : Up. 16500 : perplexity : 9.46918 : stalled 11 times (last best: 9.14892)
[2023-09-11 04:36:42] [valid] Ep. 3 : Up. 16500 : chrf : 56.1834 : stalled 26 times (last best: 56.6618)
[2023-09-11 04:36:43] [valid] Ep. 3 : Up. 16500 : ce-mean-words : 2.24804 : stalled 11 times (last best: 2.21364)
[2023-09-11 04:36:52] [valid] Ep. 3 : Up. 16500 : bleu-detok : 28.7244 : stalled 26 times (last best: 29.3573)
[2023-09-11 04:38:08] Ep. 3 : Up. 16600 : Sen. 100,851,392 : Cost 0.48424125 : Time 104.38s : 422066.08 words/s : gNorm 0.4949 : L.r. 3.0000e-04
[2023-09-11 04:39:24] Ep. 3 : Up. 16700 : Sen. 102,887,582 : Cost 0.48038274 : Time 76.02s : 586214.24 words/s : gNorm 0.4304 : L.r. 3.0000e-04
[2023-09-11 04:40:40] Ep. 3 : Up. 16800 : Sen. 104,951,959 : Cost 0.47021589 : Time 76.11s : 582376.28 words/s : gNorm 0.3774 : L.r. 3.0000e-04
[2023-09-11 04:41:57] Ep. 3 : Up. 16900 : Sen. 106,977,233 : Cost 0.48289722 : Time 77.16s : 585827.13 words/s : gNorm 0.4206 : L.r. 3.0000e-04
[2023-09-11 04:43:13] Ep. 3 : Up. 17000 : Sen. 108,999,629 : Cost 0.47646508 : Time 75.58s : 583125.81 words/s : gNorm 0.4517 : L.r. 3.0000e-04
[2023-09-11 04:43:13] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:43:13] Saving Adam parameters
[2023-09-11 04:43:14] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:43:16] [valid] Ep. 3 : Up. 17000 : perplexity : 9.62203 : stalled 12 times (last best: 9.14892)
[2023-09-11 04:43:31] [valid] Ep. 3 : Up. 17000 : chrf : 56.1015 : stalled 27 times (last best: 56.6618)
[2023-09-11 04:43:32] [valid] Ep. 3 : Up. 17000 : ce-mean-words : 2.26406 : stalled 12 times (last best: 2.21364)
[2023-09-11 04:43:42] [valid] Ep. 3 : Up. 17000 : bleu-detok : 28.2269 : stalled 27 times (last best: 29.3573)
[2023-09-11 04:44:56] Ep. 3 : Up. 17100 : Sen. 110,971,203 : Cost 0.48067573 : Time 103.05s : 419748.13 words/s : gNorm 0.4701 : L.r. 3.0000e-04
[2023-09-11 04:46:12] Ep. 3 : Up. 17200 : Sen. 112,999,613 : Cost 0.47870857 : Time 75.54s : 584255.14 words/s : gNorm 0.4414 : L.r. 3.0000e-04
[2023-09-11 04:47:27] Ep. 3 : Up. 17300 : Sen. 115,028,024 : Cost 0.47173128 : Time 75.91s : 582010.95 words/s : gNorm 0.4053 : L.r. 3.0000e-04
[2023-09-11 04:48:43] Ep. 3 : Up. 17400 : Sen. 117,054,127 : Cost 0.47336337 : Time 75.67s : 590901.73 words/s : gNorm 0.4202 : L.r. 3.0000e-04
[2023-09-11 04:49:03] Seen 117,617,657 samples
[2023-09-11 04:49:03] Starting data epoch 4 in logical epoch 4
[2023-09-11 04:49:03] [data] Shuffling data
[2023-09-11 04:49:12] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 04:50:29] Ep. 4 : Up. 17500 : Sen. 1,480,984 : Cost 0.47692963 : Time 105.41s : 421095.29 words/s : gNorm 0.4256 : L.r. 3.0000e-04
[2023-09-11 04:50:29] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:50:29] Saving Adam parameters
[2023-09-11 04:50:30] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:50:32] [valid] Ep. 4 : Up. 17500 : perplexity : 9.48157 : stalled 13 times (last best: 9.14892)
[2023-09-11 04:50:48] [valid] Ep. 4 : Up. 17500 : chrf : 56.2014 : stalled 28 times (last best: 56.6618)
[2023-09-11 04:50:49] [valid] Ep. 4 : Up. 17500 : ce-mean-words : 2.24935 : stalled 13 times (last best: 2.21364)
[2023-09-11 04:50:58] [valid] Ep. 4 : Up. 17500 : bleu-detok : 28.8258 : stalled 28 times (last best: 29.3573)
[2023-09-11 04:52:14] Ep. 4 : Up. 17600 : Sen. 3,526,973 : Cost 0.47091413 : Time 105.85s : 424498.69 words/s : gNorm 0.4167 : L.r. 3.0000e-04
[2023-09-11 04:53:31] Ep. 4 : Up. 17700 : Sen. 5,600,550 : Cost 0.47595051 : Time 76.17s : 578486.72 words/s : gNorm 0.4375 : L.r. 3.0000e-04
[2023-09-11 04:54:48] Ep. 4 : Up. 17800 : Sen. 7,608,083 : Cost 0.47765484 : Time 77.81s : 581657.09 words/s : gNorm 0.4512 : L.r. 3.0000e-04
[2023-09-11 04:56:05] Ep. 4 : Up. 17900 : Sen. 9,699,387 : Cost 0.46951371 : Time 76.18s : 582437.90 words/s : gNorm 0.3986 : L.r. 3.0000e-04
[2023-09-11 04:57:22] Ep. 4 : Up. 18000 : Sen. 11,700,507 : Cost 0.47678539 : Time 77.02s : 585343.76 words/s : gNorm 0.4318 : L.r. 3.0000e-04
[2023-09-11 04:57:22] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 04:57:22] Saving Adam parameters
[2023-09-11 04:57:22] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 04:57:24] [valid] Ep. 4 : Up. 18000 : perplexity : 9.32908 : stalled 14 times (last best: 9.14892)
[2023-09-11 04:57:39] [valid] Ep. 4 : Up. 18000 : chrf : 56.2267 : stalled 29 times (last best: 56.6618)
[2023-09-11 04:57:40] [valid] Ep. 4 : Up. 18000 : ce-mean-words : 2.23314 : stalled 14 times (last best: 2.21364)
[2023-09-11 04:57:50] [valid] Ep. 4 : Up. 18000 : bleu-detok : 28.7161 : stalled 29 times (last best: 29.3573)
[2023-09-11 04:59:05] Ep. 4 : Up. 18100 : Sen. 13,751,025 : Cost 0.48254299 : Time 103.52s : 423998.91 words/s : gNorm 0.5092 : L.r. 3.0000e-04
[2023-09-11 05:00:22] Ep. 4 : Up. 18200 : Sen. 15,702,908 : Cost 0.46675250 : Time 77.14s : 587624.80 words/s : gNorm 0.3814 : L.r. 3.0000e-04
[2023-09-11 05:01:38] Ep. 4 : Up. 18300 : Sen. 17,787,408 : Cost 0.48447189 : Time 75.32s : 573576.01 words/s : gNorm 0.4291 : L.r. 3.0000e-04
[2023-09-11 05:02:53] Ep. 4 : Up. 18400 : Sen. 19,823,404 : Cost 0.47182244 : Time 75.91s : 579879.43 words/s : gNorm 0.4295 : L.r. 3.0000e-04
[2023-09-11 05:04:10] Ep. 4 : Up. 18500 : Sen. 21,828,848 : Cost 0.47877741 : Time 76.55s : 581015.92 words/s : gNorm 0.4354 : L.r. 3.0000e-04
[2023-09-11 05:04:10] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:04:11] Saving Adam parameters
[2023-09-11 05:04:11] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:04:13] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 05:04:13] [valid] Ep. 4 : Up. 18500 : perplexity : 9.0907 : new best
[2023-09-11 05:04:27] [valid] Ep. 4 : Up. 18500 : chrf : 56.208 : stalled 30 times (last best: 56.6618)
[2023-09-11 05:04:28] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 05:04:29] [valid] Ep. 4 : Up. 18500 : ce-mean-words : 2.20725 : new best
[2023-09-11 05:04:38] [valid] Ep. 4 : Up. 18500 : bleu-detok : 28.8047 : stalled 30 times (last best: 29.3573)
[2023-09-11 05:05:54] Ep. 4 : Up. 18600 : Sen. 23,853,257 : Cost 0.47310445 : Time 104.50s : 427147.31 words/s : gNorm 0.4203 : L.r. 3.0000e-04
[2023-09-11 05:07:11] Ep. 4 : Up. 18700 : Sen. 25,930,086 : Cost 0.47449800 : Time 76.47s : 589523.15 words/s : gNorm 0.4043 : L.r. 3.0000e-04
[2023-09-11 05:08:29] Ep. 4 : Up. 18800 : Sen. 27,999,905 : Cost 0.48376888 : Time 77.64s : 583551.10 words/s : gNorm 0.4815 : L.r. 3.0000e-04
[2023-09-11 05:09:45] Ep. 4 : Up. 18900 : Sen. 30,013,301 : Cost 0.47358310 : Time 76.19s : 579990.18 words/s : gNorm 0.3977 : L.r. 3.0000e-04
[2023-09-11 05:11:00] Ep. 4 : Up. 19000 : Sen. 32,013,988 : Cost 0.47513306 : Time 75.11s : 581926.85 words/s : gNorm 0.4234 : L.r. 3.0000e-04
[2023-09-11 05:11:00] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:11:01] Saving Adam parameters
[2023-09-11 05:11:01] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:11:03] [valid] Ep. 4 : Up. 19000 : perplexity : 9.82361 : stalled 1 times (last best: 9.0907)
[2023-09-11 05:11:24] [valid] Ep. 4 : Up. 19000 : chrf : 56.3072 : stalled 31 times (last best: 56.6618)
[2023-09-11 05:11:25] [valid] Ep. 4 : Up. 19000 : ce-mean-words : 2.28479 : stalled 1 times (last best: 2.20725)
[2023-09-11 05:11:35] [valid] Ep. 4 : Up. 19000 : bleu-detok : 28.5701 : stalled 31 times (last best: 29.3573)
[2023-09-11 05:12:48] Ep. 4 : Up. 19100 : Sen. 34,054,848 : Cost 0.47650492 : Time 108.30s : 412605.80 words/s : gNorm 0.4211 : L.r. 3.0000e-04
[2023-09-11 05:14:05] Ep. 4 : Up. 19200 : Sen. 36,102,336 : Cost 0.47795889 : Time 76.72s : 578273.76 words/s : gNorm 0.4340 : L.r. 3.0000e-04
[2023-09-11 05:15:22] Ep. 4 : Up. 19300 : Sen. 38,139,526 : Cost 0.47741884 : Time 77.59s : 583233.06 words/s : gNorm 0.4443 : L.r. 3.0000e-04
[2023-09-11 05:16:39] Ep. 4 : Up. 19400 : Sen. 40,198,388 : Cost 0.47990811 : Time 76.13s : 579417.20 words/s : gNorm 0.4223 : L.r. 3.0000e-04
[2023-09-11 05:17:56] Ep. 4 : Up. 19500 : Sen. 42,266,378 : Cost 0.47211689 : Time 77.73s : 581920.59 words/s : gNorm 0.3941 : L.r. 3.0000e-04
[2023-09-11 05:17:56] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:17:57] Saving Adam parameters
[2023-09-11 05:17:57] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:18:00] [valid] Ep. 4 : Up. 19500 : perplexity : 9.45106 : stalled 2 times (last best: 9.0907)
[2023-09-11 05:18:18] [valid] Ep. 4 : Up. 19500 : chrf : 56.2041 : stalled 32 times (last best: 56.6618)
[2023-09-11 05:18:19] [valid] Ep. 4 : Up. 19500 : ce-mean-words : 2.24613 : stalled 2 times (last best: 2.20725)
[2023-09-11 05:18:29] [valid] Ep. 4 : Up. 19500 : bleu-detok : 28.6743 : stalled 32 times (last best: 29.3573)
[2023-09-11 05:19:44] Ep. 4 : Up. 19600 : Sen. 44,320,719 : Cost 0.47429773 : Time 107.70s : 412714.84 words/s : gNorm 0.4107 : L.r. 3.0000e-04
[2023-09-11 05:21:01] Ep. 4 : Up. 19700 : Sen. 46,346,736 : Cost 0.47986162 : Time 77.39s : 587669.73 words/s : gNorm 0.4507 : L.r. 3.0000e-04
[2023-09-11 05:22:18] Ep. 4 : Up. 19800 : Sen. 48,423,579 : Cost 0.46999311 : Time 76.09s : 583455.61 words/s : gNorm 0.3931 : L.r. 3.0000e-04
[2023-09-11 05:23:32] Ep. 4 : Up. 19900 : Sen. 50,421,797 : Cost 0.47174162 : Time 74.97s : 587846.64 words/s : gNorm 0.3744 : L.r. 3.0000e-04
[2023-09-11 05:24:50] Ep. 4 : Up. 20000 : Sen. 52,446,439 : Cost 0.48135871 : Time 77.42s : 578774.99 words/s : gNorm 0.4504 : L.r. 3.0000e-04
[2023-09-11 05:24:50] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:24:51] Saving Adam parameters
[2023-09-11 05:24:51] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:24:53] [valid] Ep. 4 : Up. 20000 : perplexity : 9.29394 : stalled 3 times (last best: 9.0907)
[2023-09-11 05:25:09] [valid] Ep. 4 : Up. 20000 : chrf : 55.9614 : stalled 33 times (last best: 56.6618)
[2023-09-11 05:25:10] [valid] Ep. 4 : Up. 20000 : ce-mean-words : 2.22936 : stalled 3 times (last best: 2.20725)
[2023-09-11 05:25:19] [valid] Ep. 4 : Up. 20000 : bleu-detok : 28.8239 : stalled 33 times (last best: 29.3573)
[2023-09-11 05:26:33] Ep. 4 : Up. 20100 : Sen. 54,422,958 : Cost 0.47260919 : Time 103.18s : 425495.55 words/s : gNorm 0.4287 : L.r. 3.0000e-04
[2023-09-11 05:27:48] Ep. 4 : Up. 20200 : Sen. 56,485,591 : Cost 0.47350910 : Time 74.88s : 583676.83 words/s : gNorm 0.4085 : L.r. 3.0000e-04
[2023-09-11 05:29:04] Ep. 4 : Up. 20300 : Sen. 58,483,522 : Cost 0.47610691 : Time 76.27s : 581827.65 words/s : gNorm 0.4122 : L.r. 3.0000e-04
[2023-09-11 05:30:20] Ep. 4 : Up. 20400 : Sen. 60,538,595 : Cost 0.47679818 : Time 75.26s : 575451.05 words/s : gNorm 0.4673 : L.r. 3.0000e-04
[2023-09-11 05:31:36] Ep. 4 : Up. 20500 : Sen. 62,462,615 : Cost 0.47036618 : Time 76.70s : 587180.80 words/s : gNorm 0.3953 : L.r. 3.0000e-04
[2023-09-11 05:31:36] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:31:37] Saving Adam parameters
[2023-09-11 05:31:37] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:31:39] [valid] Ep. 4 : Up. 20500 : perplexity : 9.68364 : stalled 4 times (last best: 9.0907)
[2023-09-11 05:31:55] [valid] Ep. 4 : Up. 20500 : chrf : 56.3672 : stalled 34 times (last best: 56.6618)
[2023-09-11 05:31:56] [valid] Ep. 4 : Up. 20500 : ce-mean-words : 2.27044 : stalled 4 times (last best: 2.20725)
[2023-09-11 05:32:06] [valid] Ep. 4 : Up. 20500 : bleu-detok : 28.5528 : stalled 34 times (last best: 29.3573)
[2023-09-11 05:33:20] Ep. 4 : Up. 20600 : Sen. 64,600,256 : Cost 0.47821447 : Time 103.79s : 417171.41 words/s : gNorm 0.4490 : L.r. 3.0000e-04
[2023-09-11 05:34:38] Ep. 4 : Up. 20700 : Sen. 66,588,255 : Cost 0.48050490 : Time 77.81s : 583369.32 words/s : gNorm 0.4046 : L.r. 3.0000e-04
[2023-09-11 05:35:52] Ep. 4 : Up. 20800 : Sen. 68,634,805 : Cost 0.46549410 : Time 74.43s : 581418.38 words/s : gNorm 0.3690 : L.r. 3.0000e-04
[2023-09-11 05:37:08] Ep. 4 : Up. 20900 : Sen. 70,565,040 : Cost 0.48486909 : Time 75.60s : 581213.68 words/s : gNorm 0.4392 : L.r. 3.0000e-04
[2023-09-11 05:38:25] Ep. 4 : Up. 21000 : Sen. 72,655,658 : Cost 0.47220075 : Time 76.68s : 582675.41 words/s : gNorm 0.3753 : L.r. 3.0000e-04
[2023-09-11 05:38:25] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:38:25] Saving Adam parameters
[2023-09-11 05:38:26] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:38:27] [valid] Ep. 4 : Up. 21000 : perplexity : 9.53131 : stalled 5 times (last best: 9.0907)
[2023-09-11 05:38:42] [valid] Ep. 4 : Up. 21000 : chrf : 56.3232 : stalled 35 times (last best: 56.6618)
[2023-09-11 05:38:43] [valid] Ep. 4 : Up. 21000 : ce-mean-words : 2.25458 : stalled 5 times (last best: 2.20725)
[2023-09-11 05:38:53] [valid] Ep. 4 : Up. 21000 : bleu-detok : 28.8992 : stalled 35 times (last best: 29.3573)
[2023-09-11 05:40:08] Ep. 4 : Up. 21100 : Sen. 74,649,401 : Cost 0.47341245 : Time 103.82s : 426394.37 words/s : gNorm 0.3850 : L.r. 3.0000e-04
[2023-09-11 05:41:24] Ep. 4 : Up. 21200 : Sen. 76,669,158 : Cost 0.48099446 : Time 75.16s : 579878.56 words/s : gNorm 0.4155 : L.r. 3.0000e-04
[2023-09-11 05:42:40] Ep. 4 : Up. 21300 : Sen. 78,623,908 : Cost 0.47789583 : Time 76.07s : 577534.62 words/s : gNorm 0.4012 : L.r. 3.0000e-04
[2023-09-11 05:43:57] Ep. 4 : Up. 21400 : Sen. 80,745,194 : Cost 0.46937940 : Time 77.09s : 587285.57 words/s : gNorm 0.3689 : L.r. 3.0000e-04
[2023-09-11 05:45:11] Ep. 4 : Up. 21500 : Sen. 82,784,565 : Cost 0.48403752 : Time 74.80s : 578175.99 words/s : gNorm 0.5415 : L.r. 3.0000e-04
[2023-09-11 05:45:11] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:45:12] Saving Adam parameters
[2023-09-11 05:45:12] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:45:14] [valid] Ep. 4 : Up. 21500 : perplexity : 9.92363 : stalled 6 times (last best: 9.0907)
[2023-09-11 05:45:29] [valid] Ep. 4 : Up. 21500 : chrf : 55.7172 : stalled 36 times (last best: 56.6618)
[2023-09-11 05:45:30] [valid] Ep. 4 : Up. 21500 : ce-mean-words : 2.29492 : stalled 6 times (last best: 2.20725)
[2023-09-11 05:45:39] [valid] Ep. 4 : Up. 21500 : bleu-detok : 28.1072 : stalled 36 times (last best: 29.3573)
[2023-09-11 05:46:56] Ep. 4 : Up. 21600 : Sen. 84,814,669 : Cost 0.47800669 : Time 104.36s : 430076.50 words/s : gNorm 0.4189 : L.r. 3.0000e-04
[2023-09-11 05:48:12] Ep. 4 : Up. 21700 : Sen. 86,845,556 : Cost 0.47247571 : Time 75.85s : 584144.80 words/s : gNorm 0.4126 : L.r. 3.0000e-04
[2023-09-11 05:49:29] Ep. 4 : Up. 21800 : Sen. 88,917,569 : Cost 0.47969043 : Time 77.31s : 583844.61 words/s : gNorm 0.4611 : L.r. 3.0000e-04
[2023-09-11 05:50:44] Ep. 4 : Up. 21900 : Sen. 90,918,780 : Cost 0.48129776 : Time 74.89s : 584033.00 words/s : gNorm 0.4260 : L.r. 3.0000e-04
[2023-09-11 05:52:00] Ep. 4 : Up. 22000 : Sen. 92,923,469 : Cost 0.47230512 : Time 75.68s : 582390.53 words/s : gNorm 0.3925 : L.r. 3.0000e-04
[2023-09-11 05:52:00] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:52:00] Saving Adam parameters
[2023-09-11 05:52:00] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:52:02] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-perplexity.npz
[2023-09-11 05:52:03] [valid] Ep. 4 : Up. 22000 : perplexity : 9.0497 : new best
[2023-09-11 05:52:18] [valid] Ep. 4 : Up. 22000 : chrf : 56.136 : stalled 37 times (last best: 56.6618)
[2023-09-11 05:52:19] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.best-ce-mean-words.npz
[2023-09-11 05:52:19] [valid] Ep. 4 : Up. 22000 : ce-mean-words : 2.20273 : new best
[2023-09-11 05:52:29] [valid] Ep. 4 : Up. 22000 : bleu-detok : 28.6788 : stalled 37 times (last best: 29.3573)
[2023-09-11 05:53:45] Ep. 4 : Up. 22100 : Sen. 94,926,508 : Cost 0.49688643 : Time 104.96s : 415318.78 words/s : gNorm 0.5032 : L.r. 3.0000e-04
[2023-09-11 05:55:00] Ep. 4 : Up. 22200 : Sen. 96,931,722 : Cost 0.46518004 : Time 75.28s : 582106.80 words/s : gNorm 0.3573 : L.r. 3.0000e-04
[2023-09-11 05:56:16] Ep. 4 : Up. 22300 : Sen. 98,932,849 : Cost 0.47355267 : Time 76.56s : 581625.94 words/s : gNorm 0.3889 : L.r. 3.0000e-04
[2023-09-11 05:57:31] Ep. 4 : Up. 22400 : Sen. 100,975,231 : Cost 0.49106917 : Time 74.60s : 589413.15 words/s : gNorm 0.4928 : L.r. 3.0000e-04
[2023-09-11 05:58:47] Ep. 4 : Up. 22500 : Sen. 102,966,851 : Cost 0.47297055 : Time 76.26s : 580897.44 words/s : gNorm 0.3873 : L.r. 3.0000e-04
[2023-09-11 05:58:47] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 05:58:48] Saving Adam parameters
[2023-09-11 05:58:48] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 05:58:50] [valid] Ep. 4 : Up. 22500 : perplexity : 9.20448 : stalled 1 times (last best: 9.0497)
[2023-09-11 05:59:05] [valid] Ep. 4 : Up. 22500 : chrf : 56.3469 : stalled 38 times (last best: 56.6618)
[2023-09-11 05:59:06] [valid] Ep. 4 : Up. 22500 : ce-mean-words : 2.21969 : stalled 1 times (last best: 2.20273)
[2023-09-11 05:59:15] [valid] Ep. 4 : Up. 22500 : bleu-detok : 28.9611 : stalled 38 times (last best: 29.3573)
[2023-09-11 06:00:31] Ep. 4 : Up. 22600 : Sen. 104,999,634 : Cost 0.46815878 : Time 103.52s : 425960.75 words/s : gNorm 0.3813 : L.r. 3.0000e-04
[2023-09-11 06:01:46] Ep. 4 : Up. 22700 : Sen. 107,008,974 : Cost 0.47777727 : Time 75.62s : 584597.08 words/s : gNorm 0.4121 : L.r. 3.0000e-04
[2023-09-11 06:03:01] Ep. 4 : Up. 22800 : Sen. 109,026,232 : Cost 0.47281483 : Time 74.59s : 583897.11 words/s : gNorm 0.3940 : L.r. 3.0000e-04
[2023-09-11 06:04:18] Ep. 4 : Up. 22900 : Sen. 111,104,995 : Cost 0.47287530 : Time 76.59s : 581945.74 words/s : gNorm 0.4004 : L.r. 3.0000e-04
[2023-09-11 06:05:33] Ep. 4 : Up. 23000 : Sen. 113,113,340 : Cost 0.47935024 : Time 75.67s : 583807.78 words/s : gNorm 0.4562 : L.r. 3.0000e-04
[2023-09-11 06:05:33] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:05:34] Saving Adam parameters
[2023-09-11 06:05:34] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:05:36] [valid] Ep. 4 : Up. 23000 : perplexity : 9.56825 : stalled 2 times (last best: 9.0497)
[2023-09-11 06:05:57] [valid] Ep. 4 : Up. 23000 : chrf : 55.7366 : stalled 39 times (last best: 56.6618)
[2023-09-11 06:05:57] [valid] Ep. 4 : Up. 23000 : ce-mean-words : 2.25845 : stalled 2 times (last best: 2.20273)
[2023-09-11 06:06:07] [valid] Ep. 4 : Up. 23000 : bleu-detok : 28.1397 : stalled 39 times (last best: 29.3573)
[2023-09-11 06:07:21] Ep. 4 : Up. 23100 : Sen. 115,052,724 : Cost 0.47350657 : Time 107.78s : 411354.81 words/s : gNorm 0.3719 : L.r. 3.0000e-04
[2023-09-11 06:08:35] Ep. 4 : Up. 23200 : Sen. 117,125,785 : Cost 0.47413418 : Time 74.06s : 588562.84 words/s : gNorm 0.3843 : L.r. 3.0000e-04
[2023-09-11 06:08:54] Seen 117,617,657 samples
[2023-09-11 06:08:54] Starting data epoch 5 in logical epoch 5
[2023-09-11 06:08:54] [data] Shuffling data
[2023-09-11 06:09:02] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 06:10:20] Ep. 5 : Up. 23300 : Sen. 1,442,710 : Cost 0.47374704 : Time 104.47s : 413355.77 words/s : gNorm 0.4326 : L.r. 3.0000e-04
[2023-09-11 06:11:35] Ep. 5 : Up. 23400 : Sen. 3,360,755 : Cost 0.46994328 : Time 75.06s : 587849.02 words/s : gNorm 0.4069 : L.r. 3.0000e-04
[2023-09-11 06:12:50] Ep. 5 : Up. 23500 : Sen. 5,470,869 : Cost 0.47480464 : Time 75.66s : 579371.16 words/s : gNorm 0.4053 : L.r. 3.0000e-04
[2023-09-11 06:12:50] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:12:51] Saving Adam parameters
[2023-09-11 06:12:51] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:12:53] [valid] Ep. 5 : Up. 23500 : perplexity : 9.50897 : stalled 3 times (last best: 9.0497)
[2023-09-11 06:13:10] [valid] Ep. 5 : Up. 23500 : chrf : 56.09 : stalled 40 times (last best: 56.6618)
[2023-09-11 06:13:10] [valid] Ep. 5 : Up. 23500 : ce-mean-words : 2.25224 : stalled 3 times (last best: 2.20273)
[2023-09-11 06:13:20] [valid] Ep. 5 : Up. 23500 : bleu-detok : 28.7452 : stalled 40 times (last best: 29.3573)
[2023-09-11 06:14:34] Ep. 5 : Up. 23600 : Sen. 7,455,041 : Cost 0.46992564 : Time 103.52s : 422248.42 words/s : gNorm 0.4040 : L.r. 3.0000e-04
[2023-09-11 06:15:51] Ep. 5 : Up. 23700 : Sen. 9,439,355 : Cost 0.47418058 : Time 76.81s : 585134.15 words/s : gNorm 0.3896 : L.r. 3.0000e-04
[2023-09-11 06:17:07] Ep. 5 : Up. 23800 : Sen. 11,545,327 : Cost 0.47194257 : Time 76.15s : 577856.65 words/s : gNorm 0.4095 : L.r. 3.0000e-04
[2023-09-11 06:18:22] Ep. 5 : Up. 23900 : Sen. 13,569,568 : Cost 0.47448057 : Time 75.30s : 581011.31 words/s : gNorm 0.4330 : L.r. 3.0000e-04
[2023-09-11 06:19:39] Ep. 5 : Up. 24000 : Sen. 15,541,047 : Cost 0.46767649 : Time 76.85s : 582807.67 words/s : gNorm 0.3715 : L.r. 3.0000e-04
[2023-09-11 06:19:39] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:19:40] Saving Adam parameters
[2023-09-11 06:19:40] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:19:42] [valid] Ep. 5 : Up. 24000 : perplexity : 9.30011 : stalled 4 times (last best: 9.0497)
[2023-09-11 06:19:57] [valid] Ep. 5 : Up. 24000 : chrf : 56.213 : stalled 41 times (last best: 56.6618)
[2023-09-11 06:19:58] [valid] Ep. 5 : Up. 24000 : ce-mean-words : 2.23003 : stalled 4 times (last best: 2.20273)
[2023-09-11 06:20:07] [valid] Ep. 5 : Up. 24000 : bleu-detok : 28.8377 : stalled 41 times (last best: 29.3573)
[2023-09-11 06:21:24] Ep. 5 : Up. 24100 : Sen. 17,648,354 : Cost 0.46975702 : Time 105.20s : 425517.91 words/s : gNorm 0.3882 : L.r. 3.0000e-04
[2023-09-11 06:22:42] Ep. 5 : Up. 24200 : Sen. 19,712,650 : Cost 0.47408950 : Time 77.48s : 585088.52 words/s : gNorm 0.3906 : L.r. 3.0000e-04
[2023-09-11 06:23:57] Ep. 5 : Up. 24300 : Sen. 21,656,075 : Cost 0.47156057 : Time 75.18s : 581693.19 words/s : gNorm 0.3781 : L.r. 3.0000e-04
[2023-09-11 06:25:11] Ep. 5 : Up. 24400 : Sen. 23,739,819 : Cost 0.47109550 : Time 74.73s : 577399.82 words/s : gNorm 0.3844 : L.r. 3.0000e-04
[2023-09-11 06:26:28] Ep. 5 : Up. 24500 : Sen. 25,710,861 : Cost 0.47244450 : Time 76.13s : 584522.89 words/s : gNorm 0.3999 : L.r. 3.0000e-04
[2023-09-11 06:26:28] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:26:28] Saving Adam parameters
[2023-09-11 06:26:29] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:26:30] [valid] Ep. 5 : Up. 24500 : perplexity : 9.56461 : stalled 5 times (last best: 9.0497)
[2023-09-11 06:26:46] [valid] Ep. 5 : Up. 24500 : chrf : 55.5645 : stalled 42 times (last best: 56.6618)
[2023-09-11 06:26:46] [valid] Ep. 5 : Up. 24500 : ce-mean-words : 2.25807 : stalled 5 times (last best: 2.20273)
[2023-09-11 06:26:56] [valid] Ep. 5 : Up. 24500 : bleu-detok : 28.0782 : stalled 42 times (last best: 29.3573)
[2023-09-11 06:28:11] Ep. 5 : Up. 24600 : Sen. 27,682,087 : Cost 0.47136596 : Time 103.70s : 422558.37 words/s : gNorm 0.4157 : L.r. 3.0000e-04
[2023-09-11 06:29:28] Ep. 5 : Up. 24700 : Sen. 29,794,073 : Cost 0.47220996 : Time 76.27s : 581401.11 words/s : gNorm 0.4015 : L.r. 3.0000e-04
[2023-09-11 06:30:44] Ep. 5 : Up. 24800 : Sen. 31,845,076 : Cost 0.48139820 : Time 76.87s : 586749.37 words/s : gNorm 0.4758 : L.r. 3.0000e-04
[2023-09-11 06:32:00] Ep. 5 : Up. 24900 : Sen. 33,880,769 : Cost 0.47370744 : Time 75.90s : 579112.42 words/s : gNorm 0.4069 : L.r. 3.0000e-04
[2023-09-11 06:33:16] Ep. 5 : Up. 25000 : Sen. 35,802,786 : Cost 0.46714160 : Time 76.13s : 595378.64 words/s : gNorm 0.3616 : L.r. 3.0000e-04
[2023-09-11 06:33:17] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:33:17] Saving Adam parameters
[2023-09-11 06:33:17] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:33:19] [valid] Ep. 5 : Up. 25000 : perplexity : 9.43729 : stalled 6 times (last best: 9.0497)
[2023-09-11 06:33:34] [valid] Ep. 5 : Up. 25000 : chrf : 56.4697 : stalled 43 times (last best: 56.6618)
[2023-09-11 06:33:35] [valid] Ep. 5 : Up. 25000 : ce-mean-words : 2.24467 : stalled 6 times (last best: 2.20273)
[2023-09-11 06:33:44] [valid] Ep. 5 : Up. 25000 : bleu-detok : 28.9544 : stalled 43 times (last best: 29.3573)
[2023-09-11 06:34:58] Ep. 5 : Up. 25100 : Sen. 37,911,065 : Cost 0.47847483 : Time 101.61s : 420550.74 words/s : gNorm 0.4470 : L.r. 3.0000e-04
[2023-09-11 06:36:15] Ep. 5 : Up. 25200 : Sen. 39,971,069 : Cost 0.47760281 : Time 76.47s : 584996.94 words/s : gNorm 0.3945 : L.r. 3.0000e-04
[2023-09-11 06:37:32] Ep. 5 : Up. 25300 : Sen. 41,999,862 : Cost 0.46821919 : Time 77.31s : 585040.86 words/s : gNorm 0.3858 : L.r. 3.0000e-04
[2023-09-11 06:38:47] Ep. 5 : Up. 25400 : Sen. 43,989,425 : Cost 0.48704341 : Time 74.62s : 579190.69 words/s : gNorm 0.4321 : L.r. 3.0000e-04
[2023-09-11 06:40:02] Ep. 5 : Up. 25500 : Sen. 45,991,401 : Cost 0.46704391 : Time 74.99s : 581691.49 words/s : gNorm 0.3745 : L.r. 3.0000e-04
[2023-09-11 06:40:02] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:40:02] Saving Adam parameters
[2023-09-11 06:40:02] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:40:04] [valid] Ep. 5 : Up. 25500 : perplexity : 9.2425 : stalled 7 times (last best: 9.0497)
[2023-09-11 06:40:19] [valid] Ep. 5 : Up. 25500 : chrf : 56.0064 : stalled 44 times (last best: 56.6618)
[2023-09-11 06:40:20] [valid] Ep. 5 : Up. 25500 : ce-mean-words : 2.22381 : stalled 7 times (last best: 2.20273)
[2023-09-11 06:40:30] [valid] Ep. 5 : Up. 25500 : bleu-detok : 28.5233 : stalled 44 times (last best: 29.3573)
[2023-09-11 06:41:46] Ep. 5 : Up. 25600 : Sen. 47,999,845 : Cost 0.47596580 : Time 104.34s : 423921.66 words/s : gNorm 0.3862 : L.r. 3.0000e-04
[2023-09-11 06:43:02] Ep. 5 : Up. 25700 : Sen. 50,040,641 : Cost 0.47374931 : Time 76.32s : 583959.84 words/s : gNorm 0.3919 : L.r. 3.0000e-04
[2023-09-11 06:44:19] Ep. 5 : Up. 25800 : Sen. 52,077,468 : Cost 0.47225434 : Time 76.38s : 584021.65 words/s : gNorm 0.3919 : L.r. 3.0000e-04
[2023-09-11 06:45:33] Ep. 5 : Up. 25900 : Sen. 54,071,276 : Cost 0.47661442 : Time 74.72s : 579013.80 words/s : gNorm 0.4617 : L.r. 3.0000e-04
[2023-09-11 06:46:50] Ep. 5 : Up. 26000 : Sen. 56,089,913 : Cost 0.46921775 : Time 76.61s : 581186.64 words/s : gNorm 0.3729 : L.r. 3.0000e-04
[2023-09-11 06:46:50] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:46:50] Saving Adam parameters
[2023-09-11 06:46:51] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:46:53] [valid] Ep. 5 : Up. 26000 : perplexity : 9.74225 : stalled 8 times (last best: 9.0497)
[2023-09-11 06:47:14] [valid] Ep. 5 : Up. 26000 : chrf : 56.3065 : stalled 45 times (last best: 56.6618)
[2023-09-11 06:47:15] [valid] Ep. 5 : Up. 26000 : ce-mean-words : 2.27647 : stalled 8 times (last best: 2.20273)
[2023-09-11 06:47:24] [valid] Ep. 5 : Up. 26000 : bleu-detok : 28.569 : stalled 45 times (last best: 29.3573)
[2023-09-11 06:48:39] Ep. 5 : Up. 26100 : Sen. 58,151,204 : Cost 0.47245178 : Time 109.36s : 413567.89 words/s : gNorm 0.3767 : L.r. 3.0000e-04
[2023-09-11 06:49:54] Ep. 5 : Up. 26200 : Sen. 60,230,980 : Cost 0.47158530 : Time 74.92s : 583654.74 words/s : gNorm 0.3986 : L.r. 3.0000e-04
[2023-09-11 06:51:10] Ep. 5 : Up. 26300 : Sen. 62,176,493 : Cost 0.47163433 : Time 76.17s : 584631.84 words/s : gNorm 0.3539 : L.r. 3.0000e-04
[2023-09-11 06:52:26] Ep. 5 : Up. 26400 : Sen. 64,268,047 : Cost 0.47099233 : Time 75.74s : 585092.64 words/s : gNorm 0.3793 : L.r. 3.0000e-04
[2023-09-11 06:53:42] Ep. 5 : Up. 26500 : Sen. 66,368,527 : Cost 0.47744834 : Time 76.41s : 581498.06 words/s : gNorm 0.4153 : L.r. 3.0000e-04
[2023-09-11 06:53:42] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 06:53:43] Saving Adam parameters
[2023-09-11 06:53:44] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 06:53:46] [valid] Ep. 5 : Up. 26500 : perplexity : 9.24925 : stalled 9 times (last best: 9.0497)
[2023-09-11 06:54:04] [valid] Ep. 5 : Up. 26500 : chrf : 55.9755 : stalled 46 times (last best: 56.6618)
[2023-09-11 06:54:05] [valid] Ep. 5 : Up. 26500 : ce-mean-words : 2.22454 : stalled 9 times (last best: 2.20273)
[2023-09-11 06:54:15] [valid] Ep. 5 : Up. 26500 : bleu-detok : 28.5708 : stalled 46 times (last best: 29.3573)
[2023-09-11 06:55:28] Ep. 5 : Up. 26600 : Sen. 68,290,733 : Cost 0.47429317 : Time 105.56s : 416675.80 words/s : gNorm 0.4022 : L.r. 3.0000e-04
[2023-09-11 06:56:43] Ep. 5 : Up. 26700 : Sen. 70,287,306 : Cost 0.47963434 : Time 75.31s : 581165.11 words/s : gNorm 0.4092 : L.r. 3.0000e-04
[2023-09-11 06:57:58] Ep. 5 : Up. 26800 : Sen. 72,292,638 : Cost 0.47373420 : Time 74.84s : 579396.42 words/s : gNorm 0.4052 : L.r. 3.0000e-04
[2023-09-11 06:59:13] Ep. 5 : Up. 26900 : Sen. 74,246,819 : Cost 0.47709998 : Time 74.61s : 582866.61 words/s : gNorm 0.4074 : L.r. 3.0000e-04
[2023-09-11 07:00:30] Ep. 5 : Up. 27000 : Sen. 76,263,194 : Cost 0.46942705 : Time 77.53s : 586771.22 words/s : gNorm 0.3600 : L.r. 3.0000e-04
[2023-09-11 07:00:30] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:00:31] Saving Adam parameters
[2023-09-11 07:00:31] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:00:34] [valid] Ep. 5 : Up. 27000 : perplexity : 9.5043 : stalled 10 times (last best: 9.0497)
[2023-09-11 07:00:51] [valid] Ep. 5 : Up. 27000 : chrf : 56.2391 : stalled 47 times (last best: 56.6618)
[2023-09-11 07:00:52] [valid] Ep. 5 : Up. 27000 : ce-mean-words : 2.25174 : stalled 10 times (last best: 2.20273)
[2023-09-11 07:01:02] [valid] Ep. 5 : Up. 27000 : bleu-detok : 28.7538 : stalled 47 times (last best: 29.3573)
[2023-09-11 07:02:16] Ep. 5 : Up. 27100 : Sen. 78,361,623 : Cost 0.47348094 : Time 105.58s : 417323.03 words/s : gNorm 0.3596 : L.r. 3.0000e-04
[2023-09-11 07:03:31] Ep. 5 : Up. 27200 : Sen. 80,397,690 : Cost 0.46760589 : Time 75.40s : 586307.27 words/s : gNorm 0.3500 : L.r. 3.0000e-04
[2023-09-11 07:04:48] Ep. 5 : Up. 27300 : Sen. 82,487,753 : Cost 0.47541919 : Time 76.39s : 574456.48 words/s : gNorm 0.3863 : L.r. 3.0000e-04
[2023-09-11 07:06:05] Ep. 5 : Up. 27400 : Sen. 84,462,139 : Cost 0.47592857 : Time 77.43s : 588286.63 words/s : gNorm 0.4163 : L.r. 3.0000e-04
[2023-09-11 07:07:22] Ep. 5 : Up. 27500 : Sen. 86,489,132 : Cost 0.47397634 : Time 77.15s : 576875.31 words/s : gNorm 0.3802 : L.r. 3.0000e-04
[2023-09-11 07:07:22] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:07:23] Saving Adam parameters
[2023-09-11 07:07:23] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:07:25] [valid] Ep. 5 : Up. 27500 : perplexity : 9.15246 : stalled 11 times (last best: 9.0497)
[2023-09-11 07:07:41] [valid] Ep. 5 : Up. 27500 : chrf : 56.1179 : stalled 48 times (last best: 56.6618)
[2023-09-11 07:07:42] [valid] Ep. 5 : Up. 27500 : ce-mean-words : 2.21402 : stalled 11 times (last best: 2.20273)
[2023-09-11 07:07:52] [valid] Ep. 5 : Up. 27500 : bleu-detok : 28.7277 : stalled 48 times (last best: 29.3573)
[2023-09-11 07:09:05] Ep. 5 : Up. 27600 : Sen. 88,444,764 : Cost 0.46742699 : Time 102.46s : 423206.42 words/s : gNorm 0.3880 : L.r. 3.0000e-04
[2023-09-11 07:10:20] Ep. 5 : Up. 27700 : Sen. 90,442,222 : Cost 0.47142285 : Time 75.41s : 583133.77 words/s : gNorm 0.3451 : L.r. 3.0000e-04
[2023-09-11 07:11:36] Ep. 5 : Up. 27800 : Sen. 92,475,487 : Cost 0.47490439 : Time 76.35s : 583126.25 words/s : gNorm 0.3725 : L.r. 3.0000e-04
[2023-09-11 07:12:52] Ep. 5 : Up. 27900 : Sen. 94,557,890 : Cost 0.47821912 : Time 75.07s : 583428.67 words/s : gNorm 0.4125 : L.r. 3.0000e-04
[2023-09-11 07:14:08] Ep. 5 : Up. 28000 : Sen. 96,610,941 : Cost 0.47505906 : Time 76.73s : 590665.27 words/s : gNorm 0.3717 : L.r. 3.0000e-04
[2023-09-11 07:14:08] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:14:09] Saving Adam parameters
[2023-09-11 07:14:09] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:14:11] [valid] Ep. 5 : Up. 28000 : perplexity : 9.40343 : stalled 12 times (last best: 9.0497)
[2023-09-11 07:14:26] [valid] Ep. 5 : Up. 28000 : chrf : 56.0086 : stalled 49 times (last best: 56.6618)
[2023-09-11 07:14:27] [valid] Ep. 5 : Up. 28000 : ce-mean-words : 2.24108 : stalled 12 times (last best: 2.20273)
[2023-09-11 07:14:37] [valid] Ep. 5 : Up. 28000 : bleu-detok : 28.7308 : stalled 49 times (last best: 29.3573)
[2023-09-11 07:15:54] Ep. 5 : Up. 28100 : Sen. 98,632,437 : Cost 0.47137201 : Time 105.63s : 425541.53 words/s : gNorm 0.3557 : L.r. 3.0000e-04
[2023-09-11 07:17:10] Ep. 5 : Up. 28200 : Sen. 100,688,582 : Cost 0.47993022 : Time 75.75s : 577239.34 words/s : gNorm 0.4125 : L.r. 3.0000e-04
[2023-09-11 07:18:24] Ep. 5 : Up. 28300 : Sen. 102,674,365 : Cost 0.46624178 : Time 74.50s : 593026.97 words/s : gNorm 0.3760 : L.r. 3.0000e-04
[2023-09-11 07:19:41] Ep. 5 : Up. 28400 : Sen. 104,752,728 : Cost 0.47804269 : Time 76.89s : 581731.59 words/s : gNorm 0.3787 : L.r. 3.0000e-04
[2023-09-11 07:20:57] Ep. 5 : Up. 28500 : Sen. 106,732,175 : Cost 0.47637525 : Time 76.02s : 584376.41 words/s : gNorm 0.3797 : L.r. 3.0000e-04
[2023-09-11 07:20:57] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:20:58] Saving Adam parameters
[2023-09-11 07:20:58] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:21:00] [valid] Ep. 5 : Up. 28500 : perplexity : 9.50043 : stalled 13 times (last best: 9.0497)
[2023-09-11 07:21:15] [valid] Ep. 5 : Up. 28500 : chrf : 56.2485 : stalled 50 times (last best: 56.6618)
[2023-09-11 07:21:16] [valid] Ep. 5 : Up. 28500 : ce-mean-words : 2.25134 : stalled 13 times (last best: 2.20273)
[2023-09-11 07:21:26] [valid] Ep. 5 : Up. 28500 : bleu-detok : 28.6929 : stalled 50 times (last best: 29.3573)
[2023-09-11 07:22:39] Ep. 5 : Up. 28600 : Sen. 108,833,070 : Cost 0.48193774 : Time 102.29s : 417108.99 words/s : gNorm 0.4288 : L.r. 3.0000e-04
[2023-09-11 07:23:55] Ep. 5 : Up. 28700 : Sen. 110,816,259 : Cost 0.47197807 : Time 75.44s : 584956.03 words/s : gNorm 0.4097 : L.r. 3.0000e-04
[2023-09-11 07:25:11] Ep. 5 : Up. 28800 : Sen. 112,826,414 : Cost 0.47193605 : Time 75.94s : 584788.24 words/s : gNorm 0.3760 : L.r. 3.0000e-04
[2023-09-11 07:26:29] Ep. 5 : Up. 28900 : Sen. 114,850,871 : Cost 0.47788286 : Time 77.78s : 581796.33 words/s : gNorm 0.3974 : L.r. 3.0000e-04
[2023-09-11 07:27:44] Ep. 5 : Up. 29000 : Sen. 116,926,670 : Cost 0.47548437 : Time 75.79s : 587310.44 words/s : gNorm 0.4166 : L.r. 3.0000e-04
[2023-09-11 07:27:44] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:27:45] Saving Adam parameters
[2023-09-11 07:27:45] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:27:47] [valid] Ep. 5 : Up. 29000 : perplexity : 9.21096 : stalled 14 times (last best: 9.0497)
[2023-09-11 07:28:02] [valid] Ep. 5 : Up. 29000 : chrf : 56.3682 : stalled 51 times (last best: 56.6618)
[2023-09-11 07:28:03] [valid] Ep. 5 : Up. 29000 : ce-mean-words : 2.22039 : stalled 14 times (last best: 2.20273)
[2023-09-11 07:28:12] [valid] Ep. 5 : Up. 29000 : bleu-detok : 28.9228 : stalled 51 times (last best: 29.3573)
[2023-09-11 07:28:38] Seen 117,617,657 samples
[2023-09-11 07:28:38] Starting data epoch 6 in logical epoch 6
[2023-09-11 07:28:38] [data] Shuffling data
[2023-09-11 07:28:47] [data] Done shuffling 117,618,061 sentences (cached in RAM)
[2023-09-11 07:29:57] Ep. 6 : Up. 29100 : Sen. 1,333,581 : Cost 0.46966952 : Time 132.86s : 335959.86 words/s : gNorm 0.3950 : L.r. 3.0000e-04
[2023-09-11 07:31:13] Ep. 6 : Up. 29200 : Sen. 3,293,400 : Cost 0.46503839 : Time 75.65s : 581739.62 words/s : gNorm 0.3448 : L.r. 3.0000e-04
[2023-09-11 07:32:29] Ep. 6 : Up. 29300 : Sen. 5,341,022 : Cost 0.47273311 : Time 75.72s : 586295.58 words/s : gNorm 0.3926 : L.r. 3.0000e-04
[2023-09-11 07:33:44] Ep. 6 : Up. 29400 : Sen. 7,412,116 : Cost 0.46999809 : Time 75.72s : 579008.38 words/s : gNorm 0.3573 : L.r. 3.0000e-04
[2023-09-11 07:35:00] Ep. 6 : Up. 29500 : Sen. 9,375,112 : Cost 0.47253028 : Time 75.65s : 587600.22 words/s : gNorm 0.3742 : L.r. 3.0000e-04
[2023-09-11 07:35:00] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:35:01] Saving Adam parameters
[2023-09-11 07:35:01] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:35:03] [valid] Ep. 6 : Up. 29500 : perplexity : 9.34545 : stalled 15 times (last best: 9.0497)
[2023-09-11 07:35:20] [valid] Ep. 6 : Up. 29500 : chrf : 56.18 : stalled 52 times (last best: 56.6618)
[2023-09-11 07:35:21] [valid] Ep. 6 : Up. 29500 : ce-mean-words : 2.23489 : stalled 15 times (last best: 2.20273)
[2023-09-11 07:35:30] [valid] Ep. 6 : Up. 29500 : bleu-detok : 28.9495 : stalled 52 times (last best: 29.3573)
[2023-09-11 07:36:47] Ep. 6 : Up. 29600 : Sen. 11,430,517 : Cost 0.47268033 : Time 106.88s : 420453.89 words/s : gNorm 0.3631 : L.r. 3.0000e-04
[2023-09-11 07:38:01] Ep. 6 : Up. 29700 : Sen. 13,463,032 : Cost 0.47030401 : Time 73.70s : 578995.10 words/s : gNorm 0.3736 : L.r. 3.0000e-04
[2023-09-11 07:39:18] Ep. 6 : Up. 29800 : Sen. 15,518,559 : Cost 0.47908771 : Time 77.51s : 578773.73 words/s : gNorm 0.4376 : L.r. 3.0000e-04
[2023-09-11 07:40:35] Ep. 6 : Up. 29900 : Sen. 17,566,166 : Cost 0.46783257 : Time 77.46s : 590623.58 words/s : gNorm 0.3730 : L.r. 3.0000e-04
[2023-09-11 07:41:51] Ep. 6 : Up. 30000 : Sen. 19,618,174 : Cost 0.47350830 : Time 75.63s : 580181.14 words/s : gNorm 0.3677 : L.r. 3.0000e-04
[2023-09-11 07:41:51] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:41:52] Saving Adam parameters
[2023-09-11 07:41:52] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:41:54] [valid] Ep. 6 : Up. 30000 : perplexity : 9.2881 : stalled 16 times (last best: 9.0497)
[2023-09-11 07:42:10] [valid] Ep. 6 : Up. 30000 : chrf : 56.45 : stalled 53 times (last best: 56.6618)
[2023-09-11 07:42:11] [valid] Ep. 6 : Up. 30000 : ce-mean-words : 2.22873 : stalled 16 times (last best: 2.20273)
[2023-09-11 07:42:20] [valid] Ep. 6 : Up. 30000 : bleu-detok : 28.9423 : stalled 53 times (last best: 29.3573)
[2023-09-11 07:43:38] Ep. 6 : Up. 30100 : Sen. 21,679,609 : Cost 0.47252882 : Time 106.66s : 425754.75 words/s : gNorm 0.3702 : L.r. 3.0000e-04
[2023-09-11 07:44:54] Ep. 6 : Up. 30200 : Sen. 23,659,774 : Cost 0.46677080 : Time 76.25s : 582840.03 words/s : gNorm 0.3432 : L.r. 3.0000e-04
[2023-09-11 07:46:10] Ep. 6 : Up. 30300 : Sen. 25,654,044 : Cost 0.46850276 : Time 75.88s : 587200.70 words/s : gNorm 0.3455 : L.r. 3.0000e-04
[2023-09-11 07:47:26] Ep. 6 : Up. 30400 : Sen. 27,717,502 : Cost 0.47688112 : Time 75.70s : 579038.81 words/s : gNorm 0.4286 : L.r. 3.0000e-04
[2023-09-11 07:48:41] Ep. 6 : Up. 30500 : Sen. 29,812,420 : Cost 0.46614942 : Time 75.78s : 587626.25 words/s : gNorm 0.3636 : L.r. 3.0000e-04
[2023-09-11 07:48:41] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:48:42] Saving Adam parameters
[2023-09-11 07:48:42] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:48:44] [valid] Ep. 6 : Up. 30500 : perplexity : 9.43091 : stalled 17 times (last best: 9.0497)
[2023-09-11 07:48:59] [valid] Ep. 6 : Up. 30500 : chrf : 56.3002 : stalled 54 times (last best: 56.6618)
[2023-09-11 07:49:00] [valid] Ep. 6 : Up. 30500 : ce-mean-words : 2.24399 : stalled 17 times (last best: 2.20273)
[2023-09-11 07:49:10] [valid] Ep. 6 : Up. 30500 : bleu-detok : 28.8277 : stalled 54 times (last best: 29.3573)
[2023-09-11 07:50:24] Ep. 6 : Up. 30600 : Sen. 31,755,383 : Cost 0.47693065 : Time 102.43s : 424767.50 words/s : gNorm 0.3646 : L.r. 3.0000e-04
[2023-09-11 07:51:40] Ep. 6 : Up. 30700 : Sen. 33,800,399 : Cost 0.47126630 : Time 75.85s : 581047.14 words/s : gNorm 0.3535 : L.r. 3.0000e-04
[2023-09-11 07:52:58] Ep. 6 : Up. 30800 : Sen. 35,842,921 : Cost 0.47169334 : Time 77.91s : 581014.70 words/s : gNorm 0.3826 : L.r. 3.0000e-04
[2023-09-11 07:54:14] Ep. 6 : Up. 30900 : Sen. 37,845,367 : Cost 0.46993446 : Time 75.98s : 580652.82 words/s : gNorm 0.3431 : L.r. 3.0000e-04
[2023-09-11 07:55:29] Ep. 6 : Up. 31000 : Sen. 39,926,590 : Cost 0.47394589 : Time 75.83s : 581360.60 words/s : gNorm 0.3782 : L.r. 3.0000e-04
[2023-09-11 07:55:29] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 07:55:30] Saving Adam parameters
[2023-09-11 07:55:30] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 07:55:32] [valid] Ep. 6 : Up. 31000 : perplexity : 9.54424 : stalled 18 times (last best: 9.0497)
[2023-09-11 07:55:47] [valid] Ep. 6 : Up. 31000 : chrf : 55.8972 : stalled 55 times (last best: 56.6618)
[2023-09-11 07:55:47] [valid] Ep. 6 : Up. 31000 : ce-mean-words : 2.25594 : stalled 18 times (last best: 2.20273)
[2023-09-11 07:55:57] [valid] Ep. 6 : Up. 31000 : bleu-detok : 28.6004 : stalled 55 times (last best: 29.3573)
[2023-09-11 07:57:12] Ep. 6 : Up. 31100 : Sen. 41,864,917 : Cost 0.47722626 : Time 102.86s : 423831.29 words/s : gNorm 0.3952 : L.r. 3.0000e-04
[2023-09-11 07:58:28] Ep. 6 : Up. 31200 : Sen. 43,888,720 : Cost 0.46790355 : Time 75.30s : 584833.84 words/s : gNorm 0.4035 : L.r. 3.0000e-04
[2023-09-11 07:59:45] Ep. 6 : Up. 31300 : Sen. 45,954,632 : Cost 0.47324082 : Time 76.97s : 582367.75 words/s : gNorm 0.3993 : L.r. 3.0000e-04
[2023-09-11 08:01:01] Ep. 6 : Up. 31400 : Sen. 47,999,846 : Cost 0.47412416 : Time 76.79s : 586596.96 words/s : gNorm 0.3889 : L.r. 3.0000e-04
[2023-09-11 08:02:19] Ep. 6 : Up. 31500 : Sen. 50,049,502 : Cost 0.46941414 : Time 77.32s : 583264.75 words/s : gNorm 0.3463 : L.r. 3.0000e-04
[2023-09-11 08:02:19] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 08:02:19] Saving Adam parameters
[2023-09-11 08:02:20] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 08:02:22] [valid] Ep. 6 : Up. 31500 : perplexity : 9.53533 : stalled 19 times (last best: 9.0497)
[2023-09-11 08:02:43] [valid] Ep. 6 : Up. 31500 : chrf : 56.4311 : stalled 56 times (last best: 56.6618)
[2023-09-11 08:02:44] [valid] Ep. 6 : Up. 31500 : ce-mean-words : 2.255 : stalled 19 times (last best: 2.20273)
[2023-09-11 08:02:53] [valid] Ep. 6 : Up. 31500 : bleu-detok : 29.0306 : stalled 56 times (last best: 29.3573)
[2023-09-11 08:04:07] Ep. 6 : Up. 31600 : Sen. 52,118,981 : Cost 0.46837780 : Time 108.21s : 411812.35 words/s : gNorm 0.3753 : L.r. 3.0000e-04
[2023-09-11 08:05:22] Ep. 6 : Up. 31700 : Sen. 54,134,032 : Cost 0.47183770 : Time 75.08s : 580342.01 words/s : gNorm 0.3825 : L.r. 3.0000e-04
[2023-09-11 08:06:36] Ep. 6 : Up. 31800 : Sen. 56,078,442 : Cost 0.47752008 : Time 74.22s : 578162.47 words/s : gNorm 0.3862 : L.r. 3.0000e-04
[2023-09-11 08:07:53] Ep. 6 : Up. 31900 : Sen. 58,111,140 : Cost 0.47620571 : Time 76.69s : 582288.38 words/s : gNorm 0.3873 : L.r. 3.0000e-04
[2023-09-11 08:09:09] Ep. 6 : Up. 32000 : Sen. 60,126,495 : Cost 0.47227418 : Time 76.52s : 582797.39 words/s : gNorm 0.4013 : L.r. 3.0000e-04
[2023-09-11 08:09:09] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 08:09:10] Saving Adam parameters
[2023-09-11 08:09:10] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
[2023-09-11 08:09:13] [valid] Ep. 6 : Up. 32000 : perplexity : 9.50458 : stalled 20 times (last best: 9.0497)
[2023-09-11 08:09:33] [valid] Ep. 6 : Up. 32000 : chrf : 56.0271 : stalled 57 times (last best: 56.6618)
[2023-09-11 08:09:33] [valid] Ep. 6 : Up. 32000 : ce-mean-words : 2.25177 : stalled 20 times (last best: 2.20273)
[2023-09-11 08:09:43] [valid] Ep. 6 : Up. 32000 : bleu-detok : 28.6194 : stalled 57 times (last best: 29.3573)
[2023-09-11 08:09:43] Training finished
[2023-09-11 08:09:43] Saving model weights and runtime parameters to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz
[2023-09-11 08:09:43] Saving Adam parameters
[2023-09-11 08:09:44] [training] Saving training checkpoint to /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz and /data/rw/evgeny/models/fi-en/opusprod/student-finetuned/model.npz.optimizer.npz
